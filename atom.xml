<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>小歪的博客</title>
  <subtitle>人生苦短，我学Python</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://zhangslob.github.io/"/>
  <updated>2018-05-29T16:03:32.090Z</updated>
  <id>https://zhangslob.github.io/</id>
  
  <author>
    <name>小歪</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>爬虫学到什么程度可以去找工作</title>
    <link href="https://zhangslob.github.io/2018/05/29/%E7%88%AC%E8%99%AB%E5%AD%A6%E5%88%B0%E4%BB%80%E4%B9%88%E7%A8%8B%E5%BA%A6%E5%8F%AF%E4%BB%A5%E5%8E%BB%E6%89%BE%E5%B7%A5%E4%BD%9C/"/>
    <id>https://zhangslob.github.io/2018/05/29/爬虫学到什么程度可以去找工作/</id>
    <published>2018-05-29T14:52:52.000Z</published>
    <updated>2018-05-29T16:03:32.090Z</updated>
    
    <content type="html"><![CDATA[<pre><code>这是崔斯特的第五十一篇原创文章
</code></pre><p>分享下我的经验与教训  (๑• . •๑)</p>
<p><img src="https://timgsa.baidu.com/timg?image&amp;quality=80&amp;size=b9999_10000&amp;sec=1527615838846&amp;di=6927100e3cb49201774aa07736031e9b&amp;imgtype=0&amp;src=http%3A%2F%2Fwww.btestingsky.com%2Ffiles%2Fcourse%2F2015%2F04-14%2F16211177d887256747.gif%3F4.2.0" alt=""></p>
<a id="more"></a>
<p>最近很多朋友问我，我在自学爬虫，学到什么程度可以去找工作呢？</p>
<p>这篇文章会说说我自己的心得体验，关于爬虫、关于工作，仅供参考。</p>
<h1 id="学到哪种程度"><a href="#学到哪种程度" class="headerlink" title="学到哪种程度"></a>学到哪种程度</h1><p>暂且把目标定位初级爬虫工程师，简单列一下吧：</p>
<p>（必要部分）</p>
<ol>
<li>语言选择：一般是了解Python、Java、Golang之一</li>
<li>熟悉多线程编程、网络编程、HTTP协议相关</li>
<li>开发过完整爬虫项目（最好有全站爬虫经验，这个下面会说到）</li>
<li>反爬相关，cookie、ip池、验证码等等</li>
<li>熟练使用分布式</li>
</ol>
<p>（非必要，建议）</p>
<ol>
<li>了解消息队列，如RabbitMQ、Kafka、Redis等</li>
<li>具有数据挖掘、自然语言处理、信息检索、机器学习经验</li>
<li>熟悉APP数据采集、中间人代理</li>
<li>大数据处理（Hive/MR/Spark/Storm）</li>
<li>数据库Mysql，redis，mongdb</li>
<li>熟悉Git操作、linux环境开发</li>
<li>读懂js代码，这个真的很重要</li>
</ol>
<h1 id="如何提升"><a href="#如何提升" class="headerlink" title="如何提升"></a>如何提升</h1><p>随便看看知乎上的教程就可以入门了，就Python而言，会requests当然是不够的，还需要了解scrapy和pyspider这两个框架，scrapy_redis也是需要理解原理的。</p>
<p>分布式如何搭建、如何解决其中遇到内存、速度问题。</p>
<p>参考 <a href="https://mp.weixin.qq.com/s?__biz=MzIwNjUxMTQyMA==&amp;mid=2247484093&amp;idx=1&amp;sn=f6d3d91af46830816c1ad30221504630&amp;chksm=9721ceeea05647f86376f66d75cff028f5c03c9930dbb1ca14bb3d290437be2509a4420d0f7a#rd" target="_blank" rel="external">scrapy-redis 和 scrapy 有什么区别？</a></p>
<p><img src="https://i.imgur.com/1uic8Qk.jpg" alt=""></p>
<h1 id="什么叫全站爬取"><a href="#什么叫全站爬取" class="headerlink" title="什么叫全站爬取"></a>什么叫全站爬取</h1><p>最简单的拿拉钩来举例，搜索关键词，有30页，不要以为把这30页爬完就是全站爬取了，你应该想方法把所有数据全部爬下来。</p>
<p>什么办法，通过筛选缩小范围，慢慢来就OK了。</p>
<p>同时，每个职位还会有推荐职位，再写一个采集推荐的爬虫。</p>
<p><img src="https://i.imgur.com/MuvjEAt.png" alt=""></p>
<p>这个过程需要注意的是如何去重，Mongo可以、redis也可以 </p>
<p>参考 <a href="https://mp.weixin.qq.com/s?__biz=MzIwNjUxMTQyMA==&amp;mid=2247484074&amp;idx=1&amp;sn=c5d2e89ca4f30024ed213f07cd148cb2&amp;chksm=9721cef9a05647ef3c3ba3c5344de607af087d3688dbf089dd2a45519894469fe10bbc06a277#rd" target="_blank" rel="external">Scrapy中如何提高数据的插入速度</a></p>
<h1 id="实际项目经验"><a href="#实际项目经验" class="headerlink" title="实际项目经验"></a>实际项目经验</h1><p>这个面试中肯定会被人问道，如：</p>
<ol>
<li>你爬过哪些网站</li>
<li>日均最大采集量是多少</li>
<li>你遇到哪些棘手问题，如何解决</li>
<li>等等</li>
</ol>
<p>那么怎么找项目呢？比如我要爬微博数据，去Github中搜索下，项目还算少吗？</p>
<p><img src="https://i.imgur.com/MlMcavz.png" alt=""></p>
<h1 id="语言选择"><a href="#语言选择" class="headerlink" title="语言选择"></a>语言选择</h1><p>我自己建议是Python、Java、Golang最好都了解，Java爬虫的也很多，但是网上教程几乎都是Python的，悲哀。</p>
<p>最后说下Golang，Golang真的很牛逼，说个数字，Golang可以每分钟下载网页数量 2W ，Python可以吗~~</p>
<p><img src="https://ss0.bdstatic.com/70cFvHSh_Q1YnxGkpoWK1HF6hhy/it/u=3503054989,264376367&amp;fm=11&amp;gp=0.jpg" alt=""></p>
<p>宣传下自己的刷题项目 <a href="https://github.com/zhangslob/Leetcode-Solutions" target="_blank" rel="external">Leetcode Solutions By All Language</a></p>
<h1 id="关于反爬"><a href="#关于反爬" class="headerlink" title="关于反爬"></a>关于反爬</h1><p>常见的 UA、Refer等需要了解是什么东西，有些验证的ID如何产生的，是否必要；关于IP池这块我不了解，不多说，需要注意的是如何设计拉黑机制；模拟登陆也是必要的，<a href="https://github.com/xchaoinfo/fuck-login" target="_blank" rel="external">fuck-login</a> 可以研究下代码，或者提PR。</p>
<p><img src="https://i.imgur.com/vhXq9Lw.png" alt=""></p>
<h1 id="如何判断能力足够"><a href="#如何判断能力足够" class="headerlink" title="如何判断能力足够"></a>如何判断能力足够</h1><p>很简单，给个任务，爬取知乎上所有问题。</p>
<p>你会如何思考并设计这个项目？</p>
<p>欢迎留言指出</p>
<hr>
<blockquote>
<p>以上仅为个人看法，若有不足之处请指出</p>
</blockquote>
]]></content>
    
    <summary type="html">
    
      &lt;pre&gt;&lt;code&gt;这是崔斯特的第五十一篇原创文章
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;分享下我的经验与教训  (๑• . •๑)&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://timgsa.baidu.com/timg?image&amp;amp;quality=80&amp;amp;size=b9999_10000&amp;amp;sec=1527615838846&amp;amp;di=6927100e3cb49201774aa07736031e9b&amp;amp;imgtype=0&amp;amp;src=http%3A%2F%2Fwww.btestingsky.com%2Ffiles%2Fcourse%2F2015%2F04-14%2F16211177d887256747.gif%3F4.2.0&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="爬虫" scheme="https://zhangslob.github.io/categories/%E7%88%AC%E8%99%AB/"/>
    
    
      <category term="爬虫" scheme="https://zhangslob.github.io/tags/%E7%88%AC%E8%99%AB/"/>
    
  </entry>
  
  <entry>
    <title>你写过哪些让你睡不好觉的BUG</title>
    <link href="https://zhangslob.github.io/2018/05/28/%E4%BD%A0%E5%86%99%E8%BF%87%E5%93%AA%E4%BA%9B%E8%AE%A9%E4%BD%A0%E7%9D%A1%E4%B8%8D%E5%A5%BD%E8%A7%89%E7%9A%84BUG/"/>
    <id>https://zhangslob.github.io/2018/05/28/你写过哪些让你睡不好觉的BUG/</id>
    <published>2018-05-28T15:38:35.000Z</published>
    <updated>2018-05-29T14:54:00.475Z</updated>
    
    <content type="html"><![CDATA[<pre><code>这是崔斯特的第五十篇原创文章
</code></pre><p>你写过什么有趣的BUG？  (๑• . •๑)</p>
<p><img src="https://timgsa.baidu.com/timg?image&amp;quality=80&amp;size=b9999_10000&amp;sec=1527532149198&amp;di=dcd173ae2aab83b73a2e6bfd043a8ca9&amp;imgtype=0&amp;src=http%3A%2F%2F5b0988e595225.cdn.sohucs.com%2Fimages%2F20171024%2F8d81ef9e1a014084af9aa0a4e068f75b.jpeg" alt=""></p>
<a id="more"></a>
<p>今天，聊聊 BUG。</p>
<p>今天下午发现程序中一个BUG，紧急修复之后重新上线，debug上测试没毛病，OK上正式环境。build完之后，程序一直有问题，没法读数据，头疼啊，自己看的眼睛都要瞎了，找不到原因。</p>
<p>增加更多日志，给出错的地方每一条都打印出日志来，看看到底是哪里出了问题。改完，上debug，好的没毛病，上正式环境，根据日志我大概判断出是那里的问题了，改，线下测试，debug测试，都没问题，再上正式版，还是不行。</p>
<p>这个时候已经精疲力竭了，想砸电脑！！！</p>
<p>为什么debug环境可以，正式环境不行啊？？</p>
<p><img src="https://timgsa.baidu.com/timg?image&amp;quality=80&amp;size=b9999_10000&amp;sec=1527532671810&amp;di=9d88a0db0b7cb537c79da3df79af9c3f&amp;imgtype=0&amp;src=http%3A%2F%2Fimage.woshipm.com%2Fwp-files%2F2015%2F08%2Fbug2.png" alt=""></p>
<p>然后程序就跑起来了，是的，就跑起来了。下班，回家。（已经快10点了）</p>
<p>回到家，洗完澡，写完这篇文章，再去检查日志，so far so good！！开心~</p>
<p>现在我再仔细想了想，可能是这样：线上服务器和数据库压力比较大，程序子线程没有跑起来、或者数据库没建索引、查询时间过久（明天去验证下，因为之前一直没遇到类似问题）</p>
<p>不管了，我要睡觉了。</p>
<p>来讨论下，你写过什么让你睡不好觉的BUG？</p>
<p><img src="https://timgsa.baidu.com/timg?image&amp;quality=80&amp;size=b9999_10000&amp;sec=1527532888936&amp;di=02b78519760eb95f70324934244548f2&amp;imgtype=0&amp;src=http%3A%2F%2Ftop.jobbole.com%2Fwp-content%2Fuploads%2Fsites%2F8%2F2014%2F09%2F148c6b0cefed4e594acd40957dda2c54.png" alt=""></p>
]]></content>
    
    <summary type="html">
    
      &lt;pre&gt;&lt;code&gt;这是崔斯特的第五十篇原创文章
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;你写过什么有趣的BUG？  (๑• . •๑)&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://timgsa.baidu.com/timg?image&amp;amp;quality=80&amp;amp;size=b9999_10000&amp;amp;sec=1527532149198&amp;amp;di=dcd173ae2aab83b73a2e6bfd043a8ca9&amp;amp;imgtype=0&amp;amp;src=http%3A%2F%2F5b0988e595225.cdn.sohucs.com%2Fimages%2F20171024%2F8d81ef9e1a014084af9aa0a4e068f75b.jpeg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="日常" scheme="https://zhangslob.github.io/categories/%E6%97%A5%E5%B8%B8/"/>
    
    
      <category term="BUG" scheme="https://zhangslob.github.io/tags/BUG/"/>
    
  </entry>
  
  <entry>
    <title>git大法好，push需谨慎</title>
    <link href="https://zhangslob.github.io/2018/05/26/git%E5%A4%A7%E6%B3%95%E5%A5%BD%EF%BC%8Cpush%E9%9C%80%E8%B0%A8%E6%85%8E/"/>
    <id>https://zhangslob.github.io/2018/05/26/git大法好，push需谨慎/</id>
    <published>2018-05-26T07:38:28.000Z</published>
    <updated>2018-05-26T08:13:38.658Z</updated>
    
    <content type="html"><![CDATA[<pre><code>这是崔斯特的第四十九篇原创文章
</code></pre><p>注意自己的账号安全  (๑• . •๑)</p>
<p><img src="https://i.imgur.com/lptSYQU.jpg" alt=""></p>
<a id="more"></a>
<blockquote>
<p>在每次<code>git push</code>前，请检查你的提交文件</p>
</blockquote>
<p>故事是这样来的。（我又开始讲故事了）</p>
<p>前几天在 Github上找一些资料，碰巧看到一个合适的，就把他 clone 下来，准备在本地跑着试试看效果，但是在运行的时候却发现提示错误，根绝错误提示原因我发现是缺少了一个名为<code>config.py</code>的文件。</p>
<p>经验告诉我，这应该是一个写有相关配置的文件。现在缺少了这个文件，整个程序就没法运行，自己写的话又不知道格式什么的。</p>
<p>那我该怎么办？</p>
<p><img src="https://timgsa.baidu.com/timg?image&amp;quality=80&amp;size=b9999_10000&amp;sec=1527331404813&amp;di=84868955d0e2240e0afc9c5053259864&amp;imgtype=0&amp;src=http%3A%2F%2Fimg.ishuo.cn%2Fdoc%2F1703%2F861-1F31G64602-51.jpg" alt=""></p>
<p>最后我还是找到了，在Github上。我去该项目上看到作者提交了很多次的<code>commit</code>，从历史的提交中我找到了相关信息。这是一个包含有作者相关数据库的文件，我已经通知作者，让他去删除此项目。</p>
<p>看下图，每个开源项目都会显示所有的<code>commits</code>，每次提交都会把git工作目录下所有文件提交（当然你可以指定具体的文件，我习惯<code>git add .</code>）。即使你下今天把密码删除了，但是你昨天提交的密码还是会保存到<code>commits</code>中，别人还是可以找到。</p>
<p>例如你现在看到的项目 <a href="https://github.com/zhangslob/Leetcode-Solutions" target="_blank" rel="external">Leetcode-Solutions</a> ，你可以从<code>commit</code>中进入，查看到历史<code>contributors</code>的每一次提交的完整文件， 如：<a href="https://github.com/zhangslob/Leetcode-Solutions/tree/f237fe70338eeb1e9e7c950423b254b7495ab3c7" target="_blank" rel="external">很久之前的提交</a></p>
<p><img src="https://i.imgur.com/NRDG7XU.png" alt=""></p>
<p><img src="https://i.imgur.com/8ErZTIZ.png" alt=""></p>
<p>所以看到这里，你就有必要想想自己有没有把任何个人隐私数据提交到 Github 上，如果有，建议还是删除项目吧。</p>
<p>当然，这有一个前提，就是你的项目是公开的（Public），如果是私有的（Private），就不用考虑了。</p>
<p><img src="https://i.imgur.com/DHFLCfn.png" alt=""></p>
<p>创建私有项目是收费的，一般适合公司和组织。</p>
<p>最后首尾呼应： git大法好，push需谨慎</p>
]]></content>
    
    <summary type="html">
    
      &lt;pre&gt;&lt;code&gt;这是崔斯特的第四十九篇原创文章
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;注意自己的账号安全  (๑• . •๑)&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/lptSYQU.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Git" scheme="https://zhangslob.github.io/categories/Git/"/>
    
    
      <category term="Git" scheme="https://zhangslob.github.io/tags/Git/"/>
    
  </entry>
  
  <entry>
    <title>Python最假的库：Faker</title>
    <link href="https://zhangslob.github.io/2018/05/22/Python%E6%9C%80%E5%81%87%E7%9A%84%E5%BA%93%EF%BC%9AFaker/"/>
    <id>https://zhangslob.github.io/2018/05/22/Python最假的库：Faker/</id>
    <published>2018-05-22T13:14:35.000Z</published>
    <updated>2018-05-22T13:57:47.151Z</updated>
    
    <content type="html"><![CDATA[<pre><code>这是崔斯特的第四十八篇原创文章
</code></pre><p>好假啊  (๑• . •๑)</p>
<p><img src="https://i.imgur.com/fJSZZli.jpg" alt=""></p>
<a id="more"></a>
<blockquote>
<p>先申明下，这里说的Faker和LOL的大魔王没有任何关系，只是恰好重名而已。</p>
</blockquote>
<h1 id="故事由来"><a href="#故事由来" class="headerlink" title="故事由来"></a>故事由来</h1><p>最近做一个项目时需要随机生成人的名字，百度之后，我是这样写的</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">random_first_name</span><span class="params">()</span>:</span></div><div class="line">    <span class="string">"""百家姓中选择一个"""</span></div><div class="line">    name = [<span class="string">'赵'</span>, <span class="string">'钱'</span>, <span class="string">'孙'</span>, <span class="string">'李'</span>, <span class="string">'周'</span>, <span class="string">'吴'</span>, <span class="string">'郑'</span>, <span class="string">'王'</span>, <span class="string">'冯'</span>, <span class="string">'陈'</span>, <span class="string">'褚'</span>, <span class="string">'卫'</span>, <span class="string">'蒋'</span>, <span class="string">'沈'</span>, <span class="string">'韩'</span>, <span class="string">'杨'</span>, <span class="string">'朱'</span>, <span class="string">'秦'</span>, <span class="string">'尤'</span>, <span class="string">'许'</span>, <span class="string">'何'</span>, <span class="string">'吕'</span>, <span class="string">'施'</span>, <span class="string">'张'</span>, <span class="string">'孔'</span>, <span class="string">'曹'</span>, <span class="string">'严'</span>, <span class="string">'华'</span>, <span class="string">'金'</span>, <span class="string">'魏'</span>, <span class="string">'陶'</span>, <span class="string">'姜'</span>, <span class="string">'戚'</span>, <span class="string">'谢'</span>, <span class="string">'邹'</span>, <span class="string">'喻'</span>, <span class="string">'柏'</span>, <span class="string">'水'</span>, <span class="string">'窦'</span>, <span class="string">'章'</span>, <span class="string">'云'</span>, <span class="string">'苏'</span>, <span class="string">'潘'</span>, <span class="string">'葛'</span>, <span class="string">'奚'</span>, <span class="string">'范'</span>, <span class="string">'彭'</span>, <span class="string">'郎'</span>, <span class="string">'鲁'</span>, <span class="string">'韦'</span>, <span class="string">'昌'</span>, <span class="string">'马'</span>, <span class="string">'苗'</span>, <span class="string">'凤'</span>, <span class="string">'花'</span>, <span class="string">'方'</span>, <span class="string">'俞'</span>, <span class="string">'任'</span>, <span class="string">'袁'</span>, <span class="string">'柳'</span>]</div><div class="line">    <span class="keyword">return</span> random.choice(name)</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">random_last_name</span><span class="params">()</span>:</span></div><div class="line">    <span class="string">"""生成随机汉语"""</span></div><div class="line">    head = random.randint(<span class="number">0xb0</span>, <span class="number">0xf7</span>)</div><div class="line">    body = random.randint(<span class="number">0xa1</span>, <span class="number">0xf9</span>)   <span class="comment"># 在head区号为55的那一块最后5个汉字是乱码,为了方便缩减下范围</span></div><div class="line">    val = f<span class="string">'&#123;head:x&#125;&#123;body:x&#125;'</span></div><div class="line">    str_ = bytes.fromhex(val).decode(<span class="string">'gb2312'</span>)</div><div class="line">    <span class="keyword">return</span> str_</div><div class="line"></div><div class="line">name = random_first_name() + random_last_name()</div></pre></td></tr></table></figure>
<p>前辈在review的时候说怎么这么复杂，Python中有一个专门生成各类假数据的库：Faker，你去了解下。</p>
<h1 id="Faker"><a href="#Faker" class="headerlink" title="Faker"></a>Faker</h1><p>项目地址：<a href="https://github.com/joke2k/faker" target="_blank" rel="external">faker</a></p>
<p>安装：<code>pip install Faker</code></p>
<p>中文生成假数据：<a href="https://faker.readthedocs.io/en/master/locales/zh_CN.html" target="_blank" rel="external">Language zh_CN</a></p>
<p>那么Faker能生成那些假数据了？</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> faker <span class="keyword">import</span> Faker</div><div class="line"></div><div class="line">fake = Faker(locale=<span class="string">'zh_CN'</span>)</div><div class="line"><span class="comment"># 初始化</span></div></pre></td></tr></table></figure>
<h2 id="地址"><a href="#地址" class="headerlink" title="地址"></a>地址</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">fake.street_name()</div><div class="line"><span class="comment"># '广州街</span></div><div class="line"></div><div class="line">fake.city_suffix()</div><div class="line"><span class="comment"># '县'</span></div><div class="line"></div><div class="line">fake.street_address()</div><div class="line"><span class="comment"># '香港路B座'</span></div><div class="line"></div><div class="line">fake.longitude()</div><div class="line"><span class="comment"># -98.702031</span></div><div class="line"></div><div class="line">fake.district()</div><div class="line"><span class="comment"># '璧山'</span></div></pre></td></tr></table></figure>
<h2 id="汽车"><a href="#汽车" class="headerlink" title="汽车"></a>汽车</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">fake.license_plate()</div><div class="line"><span class="comment"># HZL 767</span></div></pre></td></tr></table></figure>
<h2 id="银行"><a href="#银行" class="headerlink" title="银行"></a>银行</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">fake.bban()</div><div class="line"><span class="comment"># 'KLUX5928618542924'</span></div><div class="line"></div><div class="line">fake.bank_country()</div><div class="line"><span class="comment"># 'GB'</span></div><div class="line"></div><div class="line">fake.iban()</div><div class="line"><span class="comment"># 'GB04BPNH0448315286040'</span></div></pre></td></tr></table></figure>
<h2 id="条形码"><a href="#条形码" class="headerlink" title="条形码"></a>条形码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">fake.ean(length=<span class="number">13</span>)</div><div class="line"><span class="comment"># '0994331656275'</span></div><div class="line"></div><div class="line">fake.ean8()</div><div class="line"><span class="comment"># '51309350'</span></div><div class="line"></div><div class="line">fake.ean13()</div><div class="line"><span class="comment"># '8336323543385'</span></div></pre></td></tr></table></figure>
<h2 id="公司"><a href="#公司" class="headerlink" title="公司"></a>公司</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">fake.company_prefix()</div><div class="line"><span class="comment"># '鸿睿思博'</span></div><div class="line"></div><div class="line">fake.bs()</div><div class="line"><span class="comment"># 'embrace strategic schemas'</span></div><div class="line"></div><div class="line">fake.company_suffix()</div><div class="line"><span class="comment"># '科技有限公司'</span></div><div class="line"></div><div class="line">fake.company()</div><div class="line"><span class="comment"># '昂歌信息网络有限公司'</span></div></pre></td></tr></table></figure>
<h2 id="信用卡"><a href="#信用卡" class="headerlink" title="信用卡"></a>信用卡</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">fake.credit_card_security_code(card_type=<span class="keyword">None</span>)</div><div class="line"><span class="comment"># '360'</span></div><div class="line"></div><div class="line">fake.credit_card_full(card_type=<span class="keyword">None</span>)</div><div class="line"><span class="comment"># 'Diners Club / Carte Blanche\n林 莘\n30311852484679 10/19\nCVC: 388\n'</span></div><div class="line"></div><div class="line">fake.credit_card_number(card_type=<span class="keyword">None</span>)</div><div class="line"><span class="comment"># '30240280288941'</span></div><div class="line"></div><div class="line">fake.credit_card_expire(start=<span class="string">"now"</span>, end=<span class="string">"+10y"</span>, date_format=<span class="string">"%m/%y"</span>)</div><div class="line"><span class="comment"># '11/26'</span></div><div class="line"></div><div class="line">fake.credit_card_provider(card_type=<span class="keyword">None</span>)</div><div class="line"><span class="comment"># 'Maestro'</span></div></pre></td></tr></table></figure>
<h2 id="互联网"><a href="#互联网" class="headerlink" title="互联网"></a>互联网</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line">fake.domain_word(*args, **kwargs)</div><div class="line"><span class="comment"># 'jin'</span></div><div class="line"></div><div class="line">fake.company_email(*args, **kwargs)</div><div class="line"><span class="comment"># 'zoulei@hou.com'</span></div><div class="line"></div><div class="line">fake.free_email(*args, **kwargs)</div><div class="line"><span class="comment"># 'vxu@yahoo.com'</span></div><div class="line"></div><div class="line">fake.ipv4_private(network=<span class="keyword">False</span>, address_class=<span class="keyword">None</span>)</div><div class="line"><span class="comment"># '10.202.214.57'</span></div><div class="line"></div><div class="line">fake.ascii_safe_email(*args, **kwargs)</div><div class="line"><span class="comment"># 'baiyan@example.net'</span></div><div class="line"></div><div class="line">fake.email(*args, **kwargs)</div><div class="line"><span class="comment"># 'minggao@gmail.com'</span></div><div class="line"></div><div class="line">fake.image_url(width=<span class="keyword">None</span>, height=<span class="keyword">None</span>)</div><div class="line"><span class="comment"># 'https://www.lorempixel.com/817/102'</span></div><div class="line"></div><div class="line">fake.uri_page()</div><div class="line"><span class="comment"># 'category'</span></div><div class="line"></div><div class="line">fake.ipv4_network_class()</div><div class="line"><span class="comment"># 'c'</span></div></pre></td></tr></table></figure>
<h2 id="姓名"><a href="#姓名" class="headerlink" title="姓名"></a>姓名</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div></pre></td><td class="code"><pre><div class="line">fake.first_name_female()</div><div class="line"><span class="comment"># '秀华'</span></div><div class="line"></div><div class="line">fake.name_male()</div><div class="line"><span class="comment"># '郏杰'</span></div><div class="line"></div><div class="line">fake.suffix_female()</div><div class="line"><span class="comment"># ''</span></div><div class="line"></div><div class="line">fake.first_name()</div><div class="line"><span class="comment"># '东'</span></div><div class="line"></div><div class="line">fake.prefix_female()</div><div class="line"><span class="comment"># ''</span></div><div class="line"></div><div class="line">fake.last_name_male()</div><div class="line"><span class="comment"># '扶'</span></div><div class="line"></div><div class="line">fake.last_name()</div><div class="line"><span class="comment"># '荣'</span></div><div class="line"></div><div class="line">fake.name_female()</div><div class="line"><span class="comment"># '曹红'</span></div><div class="line"></div><div class="line">fake.suffix_male()</div><div class="line"><span class="comment"># ''</span></div><div class="line"></div><div class="line">fake.last_name_female()</div><div class="line"><span class="comment"># '辛'</span></div><div class="line"></div><div class="line">fake.last_romanized_name()</div><div class="line"><span class="comment"># 'Zhang'</span></div><div class="line"></div><div class="line">fake.first_romanized_name()</div><div class="line"><span class="comment"># 'Min'</span></div><div class="line"></div><div class="line">fake.romanized_name()</div><div class="line"><span class="comment"># 'Xiuying Qiao'</span></div><div class="line"></div><div class="line">fake.name()</div><div class="line"><span class="comment"># '钟想'</span></div></pre></td></tr></table></figure>
<h2 id="电话"><a href="#电话" class="headerlink" title="电话"></a>电话</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">fake.phone_number()</div><div class="line"><span class="comment"># '18874465626'</span></div><div class="line"></div><div class="line">fake.msisdn()</div><div class="line"><span class="comment"># '8086764507444'</span></div><div class="line"></div><div class="line">fake.phonenumber_prefix()</div><div class="line"><span class="comment"># 155</span></div></pre></td></tr></table></figure>
<h2 id="user-agent"><a href="#user-agent" class="headerlink" title="user_agent"></a>user_agent</h2><p>这个大家应该很熟悉，常用的就是 <code>fake-useragent</code>这个库<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div></pre></td><td class="code"><pre><div class="line">fake.mac_platform_token()</div><div class="line"><span class="comment"># 'Macintosh; Intel Mac OS X 10_12_1'</span></div><div class="line"></div><div class="line">fake.firefox()</div><div class="line"><span class="comment"># ('Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10_9_4; rv:1.9.4.20) '</span></div><div class="line"><span class="comment">#  'Gecko/2012-05-03 04:16:34 Firefox/3.6.10')</span></div><div class="line"></div><div class="line">fake.windows_platform_token()</div><div class="line"><span class="comment"># 'Windows 95'</span></div><div class="line"></div><div class="line">fake.safari()</div><div class="line"><span class="comment"># ('Mozilla/5.0 (iPod; U; CPU iPhone OS 3_1 like Mac OS X; sat-IN) '</span></div><div class="line"><span class="comment">#  'AppleWebKit/533.2.4 (KHTML, like Gecko) Version/3.0.5 Mobile/8B113 '</span></div><div class="line"><span class="comment">#  'Safari/6533.2.4')</span></div><div class="line"></div><div class="line">fake.chrome(version_from=<span class="number">13</span>, version_to=<span class="number">63</span>, build_from=<span class="number">800</span>, build_to=<span class="number">899</span>)</div><div class="line"><span class="comment"># ('Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/5331 (KHTML, like Gecko) '</span></div><div class="line"><span class="comment">#  'Chrome/52.0.838.0 Safari/5331')</span></div><div class="line"></div><div class="line">fake.opera()</div><div class="line"><span class="comment"># 'Opera/8.83.(X11; Linux i686; ce-RU) Presto/2.9.169 Version/10.00'</span></div><div class="line"></div><div class="line">fake.mac_processor()</div><div class="line"><span class="comment"># 'Intel'</span></div><div class="line"></div><div class="line">fake.user_agent()</div><div class="line"><span class="comment"># ('Mozilla/5.0 (Macintosh; Intel Mac OS X 10_7_9 rv:3.0; pa-IN) '</span></div><div class="line"><span class="comment">#  'AppleWebKit/532.47.6 (KHTML, like Gecko) Version/4.0.1 Safari/532.47.6')</span></div><div class="line"></div><div class="line">fake.linux_platform_token()</div><div class="line"><span class="comment"># 'X11; Linux x86_64'</span></div><div class="line"></div><div class="line">fake.linux_processor()</div><div class="line"><span class="comment"># 'i686'</span></div><div class="line"></div><div class="line">fake.internet_explorer()</div><div class="line"><span class="comment"># 'Mozilla/5.0 (compatible; MSIE 5.0; Windows NT 5.01; Trident/3.1)'</span></div></pre></td></tr></table></figure></p>
<p>这里举例的都是中文的，当然也有其他语言的，小伙伴可以去官网看看。</p>
<p>最近在和小伙伴刷题，欢迎加入 <a href="https://github.com/zhangslob/Leetcode-Solutions" target="_blank" rel="external">Leetcode Solutions By All Language</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;pre&gt;&lt;code&gt;这是崔斯特的第四十八篇原创文章
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;好假啊  (๑• . •๑)&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/fJSZZli.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="python" scheme="https://zhangslob.github.io/categories/python/"/>
    
    
      <category term="Faker" scheme="https://zhangslob.github.io/tags/Faker/"/>
    
  </entry>
  
  <entry>
    <title>强大的异步爬虫 with aiohttp</title>
    <link href="https://zhangslob.github.io/2018/05/16/%E5%BC%BA%E5%A4%A7%E7%9A%84%E5%BC%82%E6%AD%A5%E7%88%AC%E8%99%AB-aiohttp/"/>
    <id>https://zhangslob.github.io/2018/05/16/强大的异步爬虫-aiohttp/</id>
    <published>2018-05-16T09:00:07.000Z</published>
    <updated>2018-05-16T13:39:40.499Z</updated>
    
    <content type="html"><![CDATA[<pre><code>这是崔斯特的第四十七篇原创文章
</code></pre><p>异步了解下  (๑• . •๑)</p>
<p><img src="https://i.imgur.com/gBlZ2Mq.jpg" alt=""></p>
<a id="more"></a>
<hr>
<p>看到现在网络上大多讲的都是requests、scrapy，却没有说到爬虫中的神器：<strong>aiohttp</strong></p>
<h1 id="aiohttp-介绍"><a href="#aiohttp-介绍" class="headerlink" title="aiohttp 介绍"></a>aiohttp 介绍</h1><p>aiohttp是什么，官网上有这样一句话介绍：<code>Async HTTP client/server for asyncio and Python</code>，翻译过来就是 <code>asyncio和Python的异步HTTP客户端/服务器</code></p>
<p>主要特点是：</p>
<ol>
<li>支持客户端和HTTP服务器。 </li>
<li>无需使用Callback Hell即可支持Server WebSockets和Client WebSockets。 </li>
<li>Web服务器具有中间件，信号和可插拔路由。</li>
</ol>
<p>emmmm，好吧，还是来看代码吧</p>
<p>Client example:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> aiohttp</div><div class="line"><span class="keyword">import</span> asyncio</div><div class="line"></div><div class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">fetch</span><span class="params">(session, url)</span>:</span></div><div class="line">    <span class="keyword">async</span> <span class="keyword">with</span> session.get(url) <span class="keyword">as</span> response:</div><div class="line">        <span class="keyword">return</span> <span class="keyword">await</span> response.text()</div><div class="line"></div><div class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></div><div class="line">    <span class="keyword">async</span> <span class="keyword">with</span> aiohttp.ClientSession() <span class="keyword">as</span> session:</div><div class="line">        html = <span class="keyword">await</span> fetch(session, <span class="string">'http://httpbin.org/headers'</span>)</div><div class="line">        print(html)</div><div class="line"></div><div class="line">loop = asyncio.get_event_loop()</div><div class="line">loop.run_until_complete(main())</div></pre></td></tr></table></figure>
<p>output:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&#123;<span class="string">"headers"</span>:&#123;<span class="string">"Accept"</span>:<span class="string">"*/*"</span>,<span class="string">"Accept-Encoding"</span>:<span class="string">"gzip, deflate"</span>,<span class="string">"Connection"</span>:<span class="string">"close"</span>,<span class="string">"Host"</span>:<span class="string">"httpbin.org"</span>,<span class="string">"User-Agent"</span>:<span class="string">"Python/3.6 aiohttp/3.2.1"</span>&#125;&#125;</div></pre></td></tr></table></figure>
<p>Server example:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> aiohttp <span class="keyword">import</span> web</div><div class="line"></div><div class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">handle</span><span class="params">(request)</span>:</span></div><div class="line">    name = request.match_info.get(<span class="string">'name'</span>, <span class="string">"Anonymous"</span>)</div><div class="line">    text = <span class="string">"Hello, "</span> + name</div><div class="line">    <span class="keyword">return</span> web.Response(text=text)</div><div class="line"></div><div class="line">app = web.Application()</div><div class="line">app.add_routes([web.get(<span class="string">'/'</span>, handle),</div><div class="line">                web.get(<span class="string">'/&#123;name&#125;'</span>, handle)])</div><div class="line"></div><div class="line">web.run_app(app)</div></pre></td></tr></table></figure>
<p>output:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">======== Running on http://0.0.0.0:8080 ========</div><div class="line">(Press CTRL+C to quit)</div></pre></td></tr></table></figure>
<h1 id="aiohttp-与-requests"><a href="#aiohttp-与-requests" class="headerlink" title="aiohttp 与 requests"></a>aiohttp 与 requests</h1><p>去翻一下官方文档 <a href="https://aiohttp.readthedocs.io/en/stable/client_quickstart.html#" target="_blank" rel="external">Client Quickstart</a>，让我感觉非常熟悉，很多用法和requests相似。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">async</span> <span class="keyword">with</span> aiohttp.ClientSession() <span class="keyword">as</span> session:</div><div class="line">    <span class="keyword">async</span> <span class="keyword">with</span> session.get(<span class="string">'http://httpbin.org/get'</span>) <span class="keyword">as</span> resp:</div><div class="line">        print(resp.status)</div><div class="line">        print(<span class="keyword">await</span> resp.text())</div></pre></td></tr></table></figure>
<p>首先，官方推荐使用<a href="https://aiohttp.readthedocs.io/en/stable/client_reference.html#aiohttp.ClientSession" target="_blank" rel="external">ClientSession</a>来管理会话，这不就是<code>requests</code>中的<code>session</code>吗？用法也类似，使用<code>session.get()</code>去发送<code>get</code>请求，返回的<code>resp</code>中就有我们所需要的数据了，用法也和<code>requests</code>一样，<code>text（）</code>文本，<code>.json()</code>直接打印返回的<code>json</code>数据，<code>headers</code>什么的也一样，更多内容参考官方文档<a href="https://aiohttp.readthedocs.io/en/stable/client_reference.html#response-object" target="_blank" rel="external">Response object</a></p>
<p>既然已经有<code>requests</code>了，那为什么还要说<code>aiohttp</code>了？重点来了，<code>aiohttp</code>是异步的。在python3.5中，加入了<code>asyncio/await</code> 关键字，使得回调的写法更加直观和人性化。而<code>aiohttp</code>是一个提供异步web服务的库，<code>asyncio</code>可以实现单线程并发IO操作。</p>
<p><code>requests</code>写爬虫是同步的，是等待网页下载好才会执行下面的解析、入库操作，如果在下载网页时间太长会导致阻塞，使用<code>multiprocessing</code>或者 <code>threading</code>加速爬虫也是一种方法。</p>
<p>我们现在使用的<code>aiohttp</code>是异步的，简单来说，就是不需要等待，你尽管去下载网页就好了，我不用傻傻的等待你完成才进行下一步，我还有别的活要干。这样就极大的提高了下载网页的效率。</p>
<p>另外，<code>Scrapy</code>也是异步的，是基于Twisted事件驱动的。在任何情况下，都不要写阻塞的代码。阻塞的代码包括：</p>
<ol>
<li>访问文件、数据库或者Web</li>
<li>产生新的进程并需要处理新进程的输出，如运行shell命令</li>
<li>执行系统层次操作的代码，如等待系统队列</li>
</ol>
<h1 id="代码实例"><a href="#代码实例" class="headerlink" title="代码实例"></a>代码实例</h1><p>这里是使用<code>aiohttp</code>的一个爬虫实例</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> asyncio</div><div class="line"></div><div class="line"><span class="keyword">import</span> aiohttp</div><div class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</div><div class="line"></div><div class="line"><span class="keyword">import</span> logging</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">AsnycGrab</span><span class="params">(object)</span>:</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, url_list, max_threads)</span>:</span></div><div class="line"></div><div class="line">        self.urls = url_list</div><div class="line">        self.results = &#123;&#125;</div><div class="line">        self.max_threads = max_threads</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__parse_results</span><span class="params">(self, url, html)</span>:</span></div><div class="line"></div><div class="line">        <span class="keyword">try</span>:</div><div class="line">            soup = BeautifulSoup(html, <span class="string">'html.parser'</span>)</div><div class="line">            title = soup.find(<span class="string">'title'</span>).get_text()</div><div class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</div><div class="line">            <span class="keyword">raise</span> e</div><div class="line"></div><div class="line">        <span class="keyword">if</span> title:</div><div class="line">            self.results[url] = title</div><div class="line"></div><div class="line">    <span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">get_body</span><span class="params">(self, url)</span>:</span></div><div class="line">        <span class="keyword">async</span> <span class="keyword">with</span> aiohttp.ClientSession() <span class="keyword">as</span> session:</div><div class="line">            <span class="keyword">async</span> <span class="keyword">with</span> session.get(url, timeout=<span class="number">30</span>) <span class="keyword">as</span> response:</div><div class="line">                <span class="keyword">assert</span> response.status == <span class="number">200</span></div><div class="line">                html = <span class="keyword">await</span> response.read()</div><div class="line">                <span class="keyword">return</span> response.url, html</div><div class="line"></div><div class="line">    <span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">get_results</span><span class="params">(self, url)</span>:</span></div><div class="line">        url, html = <span class="keyword">await</span> self.get_body(url)</div><div class="line">        self.__parse_results(url, html)</div><div class="line">        <span class="keyword">return</span> <span class="string">'Completed'</span></div><div class="line"></div><div class="line">    <span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">handle_tasks</span><span class="params">(self, task_id, work_queue)</span>:</span></div><div class="line">        <span class="keyword">while</span> <span class="keyword">not</span> work_queue.empty():</div><div class="line">            current_url = <span class="keyword">await</span> work_queue.get()</div><div class="line">            <span class="keyword">try</span>:</div><div class="line">                task_status = <span class="keyword">await</span> self.get_results(current_url)</div><div class="line">            <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</div><div class="line">                logging.exception(<span class="string">'Error for &#123;&#125;'</span>.format(current_url), exc_info=<span class="keyword">True</span>)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">eventloop</span><span class="params">(self)</span>:</span></div><div class="line">        q = asyncio.Queue()</div><div class="line">        [q.put_nowait(url) <span class="keyword">for</span> url <span class="keyword">in</span> self.urls]</div><div class="line">        loop = asyncio.get_event_loop()</div><div class="line">        tasks = [self.handle_tasks(task_id, q, ) <span class="keyword">for</span> task_id <span class="keyword">in</span> range(self.max_threads)]</div><div class="line">        loop.run_until_complete(asyncio.wait(tasks))</div><div class="line">        loop.close()</div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line">    async_example = AsnycGrab([<span class="string">'http://edmundmartin.com'</span>,</div><div class="line">               <span class="string">'https://www.udemy.com'</span>,</div><div class="line">               <span class="string">'https://github.com/'</span>,</div><div class="line">               <span class="string">'https://zhangslob.github.io/'</span>,</div><div class="line">               <span class="string">'https://www.zhihu.com/'</span>], <span class="number">5</span>)</div><div class="line">    async_example.eventloop()</div><div class="line">    print(async_example.results)</div></pre></td></tr></table></figure>
<p>需要注意的是，你需要时刻在你的代码中使用异步操作，你如果在代码中使用同步操作，爬虫并不会报错，但是速度可能会受影响。</p>
<h1 id="其他异步库"><a href="#其他异步库" class="headerlink" title="其他异步库"></a>其他异步库</h1><p>因为爬虫不仅仅只有下载这块，还会有操作数据库，这里提供两个异步库：<code>aioredis</code>、<code>motor</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> asyncio</div><div class="line"><span class="keyword">import</span> aioredis</div><div class="line"></div><div class="line">loop = asyncio.get_event_loop()</div><div class="line"></div><div class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">go</span><span class="params">()</span>:</span></div><div class="line">    conn = <span class="keyword">await</span> aioredis.create_connection(</div><div class="line">        <span class="string">'redis://localhost'</span>, loop=loop)</div><div class="line">    <span class="keyword">await</span> conn.execute(<span class="string">'set'</span>, <span class="string">'my-key'</span>, <span class="string">'value'</span>)</div><div class="line">    val = <span class="keyword">await</span> conn.execute(<span class="string">'get'</span>, <span class="string">'my-key'</span>)</div><div class="line">    print(val)</div><div class="line">    conn.close()</div><div class="line">    <span class="keyword">await</span> conn.wait_closed()</div><div class="line">loop.run_until_complete(go())</div><div class="line"><span class="comment"># will print 'value'</span></div></pre></td></tr></table></figure>
<p>文档：<a href="http://aioredis.readthedocs.io/en/v1.1.0/index.html" target="_blank" rel="external">aioredis</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> motor.motor_asyncio</div><div class="line"></div><div class="line">client = motor.motor_asyncio.AsyncIOMotorClient(<span class="string">'mongodb://localhost:27017'</span>)</div><div class="line"></div><div class="line">db = client[<span class="string">'test_database'</span>]</div><div class="line">collection = db[<span class="string">'test_collection'</span>]</div><div class="line"></div><div class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">do_insert</span><span class="params">()</span>:</span></div><div class="line">    document = &#123;<span class="string">'key'</span>: <span class="string">'value'</span>&#125;</div><div class="line">    result = <span class="keyword">await</span> db.test_collection.insert_one(document)</div><div class="line">    print(<span class="string">'result %s'</span> % repr(result.inserted_id))</div><div class="line">    </div><div class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">do_find_one</span><span class="params">()</span>:</span></div><div class="line">    document = <span class="keyword">await</span> db.test_collection.find_one(&#123;<span class="string">'i'</span>: &#123;<span class="string">'$lt'</span>: <span class="number">1</span>&#125;&#125;)</div><div class="line">    pprint.pprint(document)</div></pre></td></tr></table></figure>
<p>文档：<a href="https://motor.readthedocs.io/en/stable/index.html" target="_blank" rel="external">motor</a></p>
<p><img src="https://motor.readthedocs.io/en/stable/_images/motor.png" alt=""></p>
<p>本文仅仅介绍了<code>aiohttp</code>作为<code>Client</code>的用法， 有兴趣的朋友可以去研究下作为<code>Server</code>的用法，同样很强大。</p>
]]></content>
    
    <summary type="html">
    
      &lt;pre&gt;&lt;code&gt;这是崔斯特的第四十七篇原创文章
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;异步了解下  (๑• . •๑)&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/gBlZ2Mq.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Leetcode" scheme="https://zhangslob.github.io/categories/Leetcode/"/>
    
    
      <category term="Leetcode" scheme="https://zhangslob.github.io/tags/Leetcode/"/>
    
  </entry>
  
  <entry>
    <title>Leetcode Solutions（一） two-sum</title>
    <link href="https://zhangslob.github.io/2018/05/15/Leetcode%20Solutions%EF%BC%88%E4%B8%80%EF%BC%89/"/>
    <id>https://zhangslob.github.io/2018/05/15/Leetcode Solutions（一）/</id>
    <published>2018-05-15T10:22:26.000Z</published>
    <updated>2018-05-15T15:58:09.668Z</updated>
    
    <content type="html"><![CDATA[<pre><code>这是崔斯特的第四十六篇原创文章
</code></pre><p>开始刷题咯  (๑• . •๑)</p>
<p><img src="https://ss0.bdstatic.com/70cFvHSh_Q1YnxGkpoWK1HF6hhy/it/u=3503054989,264376367&amp;fm=11&amp;gp=0.jpg" alt=""></p>
<a id="more"></a>
<p><a href="https://leetcode-cn.com/problems/two-sum/description/" target="_blank" rel="external">Two Sum</a></p>
<h1 id="题目"><a href="#题目" class="headerlink" title="题目"></a>题目</h1><p>给定一个整数数组和一个目标值，找出数组中和为目标值的两个数。</p>
<p>你可以假设每个输入只对应一种答案，且同样的元素不能被重复利用。</p>
<p>示例:<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">给定 nums = [<span class="number">2</span>, <span class="number">7</span>, <span class="number">11</span>, <span class="number">15</span>], target = <span class="number">9</span></div><div class="line"></div><div class="line">因为 nums[<span class="number">0</span>] + nums[<span class="number">1</span>] = <span class="number">2</span> + <span class="number">7</span> = <span class="number">9</span></div><div class="line">所以返回 [<span class="number">0</span>, <span class="number">1</span>]</div></pre></td></tr></table></figure></p>
<h1 id="解题思路"><a href="#解题思路" class="headerlink" title="解题思路"></a>解题思路</h1><h2 id="Go"><a href="#Go" class="headerlink" title="Go"></a>Go</h2><p><code>a + b = target</code></p>
<p>也可以看成是</p>
<p><code>a = target - b</code></p>
<p>在map[整数]整数的序号中，可以查询到a的序号。这样就不用嵌套两个for循环了。</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">func</span> <span class="title">twoSum</span><span class="params">(nums []<span class="keyword">int</span>, target <span class="keyword">int</span>)</span> []<span class="title">int</span></span> &#123;</div><div class="line">	m := <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="keyword">int</span>]<span class="keyword">int</span>, <span class="built_in">len</span>(nums))</div><div class="line">	<span class="keyword">for</span> i, b := <span class="keyword">range</span> nums &#123;</div><div class="line">		<span class="keyword">if</span> j, ok := m[target-b]; ok &#123;</div><div class="line">			<span class="keyword">return</span> []<span class="keyword">int</span>&#123;j, i&#125;</div><div class="line">		&#125;</div><div class="line">		m[nums[i]] = i</div><div class="line">	&#125;</div><div class="line">	<span class="keyword">return</span> <span class="literal">nil</span></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="Python"><a href="#Python" class="headerlink" title="Python"></a>Python</h2><ol>
<li>由于要找到符合题意的数组元素的下标，所以先要将原来的数组深拷贝一份，然后排序。</li>
<li>然后在排序后的数组中找两个数使它们相加为target。这个思路比较明显：使用两个指针，一个指向头，一个指向尾，两个指针向中间移动并检查两个指针指向的数的和是否为target。如果找到了这两个数，再将这两个数在原数组中的位置找出来就可以了。</li>
<li>要注意的一点是：在原来数组中找下标时，需要一个从头找，一个从尾找，要不无法通过。如这个例子：numbers=[0,1,2,0]; target=0。如果都从头开始找，就会有问题。</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">twoSum</span><span class="params">(self, nums, target)</span>:</span></div><div class="line">        <span class="keyword">if</span> len(nums) &lt;= <span class="number">1</span>:</div><div class="line">            <span class="keyword">return</span> <span class="keyword">False</span></div><div class="line">        d = dict()</div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(nums)):</div><div class="line">            <span class="keyword">if</span> nums[i] <span class="keyword">in</span> d:</div><div class="line">                <span class="keyword">return</span> [d[nums[i]], i]</div><div class="line">            <span class="keyword">else</span>:</div><div class="line">                d[target - nums[i]] = i</div></pre></td></tr></table></figure>
]]></content>
    
    <summary type="html">
    
      &lt;pre&gt;&lt;code&gt;这是崔斯特的第四十六篇原创文章
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;开始刷题咯  (๑• . •๑)&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://ss0.bdstatic.com/70cFvHSh_Q1YnxGkpoWK1HF6hhy/it/u=3503054989,264376367&amp;amp;fm=11&amp;amp;gp=0.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Leetcode" scheme="https://zhangslob.github.io/categories/Leetcode/"/>
    
    
      <category term="Leetcode" scheme="https://zhangslob.github.io/tags/Leetcode/"/>
    
  </entry>
  
  <entry>
    <title>告别win10，拥抱linux</title>
    <link href="https://zhangslob.github.io/2018/05/12/%E5%91%8A%E5%88%ABwin10%EF%BC%8C%E6%8B%A5%E6%8A%B1linux/"/>
    <id>https://zhangslob.github.io/2018/05/12/告别win10，拥抱linux/</id>
    <published>2018-05-12T05:49:33.000Z</published>
    <updated>2018-05-12T06:39:43.144Z</updated>
    
    <content type="html"><![CDATA[<pre><code>这是崔斯特的第四十五篇原创文章
</code></pre><p>安装linux操作系统  (๑• . •๑)</p>
<p><img src="http://p8eyj0cpn.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E6%88%AA%E5%9B%BE_Desktop_20180512132633.png" alt=""></p>
<a id="more"></a>
<h1 id="win10-升级"><a href="#win10-升级" class="headerlink" title="win10 升级"></a>win10 升级</h1><p>先问你一个问题，你讨厌win10升级系统吗？</p>
<p>我的回答：是，明明已经把自动更新关闭了，可是还是会有“易升”，win10易升一直卸载不掉。所以就想试试别的系统。</p>
<p>linux是最好的选择。黑苹果暂时不考虑。</p>
<p><img src="http://img.mp.itc.cn/upload/20170408/35c850c176b9447da3fbb3d303172f2a_th.jpg" alt=""></p>
<h1 id="喜欢linux的理由"><a href="#喜欢linux的理由" class="headerlink" title="喜欢linux的理由"></a>喜欢linux的理由</h1><p><img src="http://p8eyj0cpn.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E6%88%AA%E5%9B%BE_Desktop_20180512132633.png" alt=""></p>
<blockquote>
<p>深度桌面</p>
</blockquote>
<p><img src="http://p8eyj0cpn.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E6%88%AA%E5%9B%BE_deepin-terminal_20180512133029.png" alt=""></p>
<blockquote>
<p>深度终端（配合zsh超赞的）</p>
</blockquote>
<p>除了颜值外，程序兼容性会更好，安装各种东西会很方便。作为一名程序员，熟悉linux下基本操作也是必要的。</p>
<blockquote>
<p>我自己试过，爬虫会跑的更快。 手动滑稽</p>
</blockquote>
<h1 id="选择linux哪个版本"><a href="#选择linux哪个版本" class="headerlink" title="选择linux哪个版本"></a>选择linux哪个版本</h1><p>目前我使用过deepin和ubuntu18，对于完全的小白来说，我推荐deepin也就是深度操作系统，深度商店收入的应用可以基本满足，ubuntu很多应用安装起来比较麻烦，如果你喜欢折腾，那就上手ubuntu吧。</p>
<p>如果你和我一样 喜欢xxx，那就试试deepin和ubuntu18共存。</p>
<p>我现在的开机界面（渣渣像素）</p>
<p><img src="http://p8eyj0cpn.bkt.clouddn.com/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20180512135314.jpg" alt=""></p>
<h1 id="如何安装linux"><a href="#如何安装linux" class="headerlink" title="如何安装linux"></a>如何安装linux</h1><h2 id="安装deepin"><a href="#安装deepin" class="headerlink" title="安装deepin"></a>安装deepin</h2><p>使用U盘安装</p>
<p>先去下载：</p>
<ol>
<li><a href="http://cdimage.deepin.com/releases/15.5/deepin-15.5-amd64.iso" target="_blank" rel="external">ISO文件</a></li>
<li><a href="http://cdimage.deepin.com/applications/deepin-boot-maker/windows/deepin-boot-maker.exe" target="_blank" rel="external">深度启动盘制作工具</a></li>
</ol>
<p>然后安装启动盘制作工具，然后选择刚才下载的ISO文件，下一步选择你的U盘，然后就开始安装了。</p>
<p><img src="http://p8eyj0cpn.bkt.clouddn.com/%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20180512135903.png" alt=""></p>
<p><img src="https://www.deepin.org/wp-content/uploads/2016/12/deepin-boot-maker-2-cn.png" alt=""><br><img src="https://www.deepin.org/wp-content/uploads/2016/12/deepin-boot-maker-3-cn.png" alt=""></p>
<p>下一步，重启电脑，一般情况下电脑默认是从硬盘启动，因此，在使用U盘安装系统之前，您需要先进入电脑的BIOS界面将U盘设置为第一启动项。</p>
<p>台式机一般为 Delete 键、笔记本一般为 F2  或 F10 或 F12 键，即可进入 BIOS 设置界面。</p>
<ol>
<li>将深度操作系统光盘插入电脑光驱中。</li>
<li>启动电脑，将光盘设置为第一启动项。</li>
<li>进入安装界面，选择需要安装的语言。</li>
</ol>
<p><img src="https://www.deepin.org/wp-content/uploads/2016/12/deepin-installer1.png" alt=""></p>
<p>如果还不会，这里有官方录制的视频哦 <a href="https://www.bilibili.com/video/av16993752/" target="_blank" rel="external">深度安装器+深度探索频道第七期+深度操作系统官方出品</a></p>
<p>还有一种更加简单的方式就是下载 <a href="http://cdimage.deepin.com/applications/deepin-boot-maker/windows/deepin-system-installer.exe" target="_blank" rel="external">深度系统安装器</a></p>
<p><img src="https://i.imgur.com/mpkCwJg.png" alt=""></p>
<p>然后就是傻瓜操作了，记得关闭下 <a href="http://www.yxswz.com/x64bug.html" target="_blank" rel="external">安全启动</a></p>
<blockquote>
<p>小歪并不推荐使用第二种方式安装，在笔记本上怎么都没有效果，在台式上一次成功。所以大家有U盘的尽量使用U盘吧</p>
</blockquote>
<h2 id="安装ubuntu"><a href="#安装ubuntu" class="headerlink" title="安装ubuntu"></a>安装ubuntu</h2><p>需要用到上面提到过的<a href="http://cdimage.deepin.com/applications/deepin-boot-maker/windows/deepin-boot-maker.exe" target="_blank" rel="external">深度启动盘制作工具</a>，然后去下载 <a href="https://www.ubuntu.com/download/desktop" target="_blank" rel="external">ISO文件</a>，然后就是和上面安装方法一样的，进行操作即可。</p>
<p>有没有很简单。</p>
<p><img src="https://i.imgur.com/u3gBHqc.png" alt=""></p>
<blockquote>
<p>我的ubuntu界面，用得少，所以没美化</p>
</blockquote>
<h1 id="感受"><a href="#感受" class="headerlink" title="感受"></a>感受</h1><p>我使用deepin有一个月了，写代码用deepin，家里的台式还是win7，因为deepin虽然有steam，但是吃鸡不支持在linux下运行。</p>
<p>deepin完全可以满足我的办公需求，Pycharm、sublime、typora、chrome、网易云音乐等等都有，用起来很舒服，至少现在是这样感觉。但是有时候deepin也会卡死。</p>
<p>强烈建议上手linux，可以学到很多命令行操作，安装deepin就好，到时候你的电脑会Windows与deepin共存，根据场景选择系统。</p>
<p>有时间写一篇deepin美化与安装应用相关的东西，看到这一定要点赞哦。</p>
<p><img src="https://i.imgur.com/xbmqUXs.jpg" alt=""></p>
]]></content>
    
    <summary type="html">
    
      &lt;pre&gt;&lt;code&gt;这是崔斯特的第四十五篇原创文章
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;安装linux操作系统  (๑• . •๑)&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://p8eyj0cpn.bkt.clouddn.com/%E6%B7%B1%E5%BA%A6%E6%88%AA%E5%9B%BE_Desktop_20180512132633.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="linux" scheme="https://zhangslob.github.io/categories/linux/"/>
    
    
      <category term="linux" scheme="https://zhangslob.github.io/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>linux下安装python3.6</title>
    <link href="https://zhangslob.github.io/2018/05/11/linux%E4%B8%8B%E5%AE%89%E8%A3%85python3-6/"/>
    <id>https://zhangslob.github.io/2018/05/11/linux下安装python3-6/</id>
    <published>2018-05-11T14:26:54.000Z</published>
    <updated>2018-05-11T14:35:28.614Z</updated>
    
    <content type="html"><![CDATA[<pre><code>这是崔斯特的第四十四篇原创文章
</code></pre><p>linux操作  (๑• . •๑)</p>
<p><img src="https://i.imgur.com/lJ8ygSI.jpg" alt=""></p>
<a id="more"></a>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line">sudo sed -i <span class="string">'s\archive.ubuntu.com\mirrors.aliyun.com\g'</span> /etc/apt/sources.list</div><div class="line">sudo apt-get update</div><div class="line"><span class="built_in">cd</span> /home/</div><div class="line">sudo apt-get install gcc  make zlib1g-dev -y</div><div class="line">sudo apt-get install  libbz2-dev libsqlite3-dev  libxml2-dev  libffi-dev libssl-dev -y</div><div class="line">sudo apt install wget -y</div><div class="line">wget http://mirrors.sohu.com/python/3.6.2/Python-3.6.2.tgz <span class="comment"># 可以换成你想要的版本</span></div><div class="line">tar -xvf Python-3.6.2.tgz</div><div class="line"><span class="built_in">cd</span> Python-3.6.2</div><div class="line">./configure --prefix=/home/usr/python36/</div><div class="line">sudo make</div><div class="line">sudo make install</div><div class="line"><span class="built_in">cd</span> ../usr/python36/bin/</div><div class="line">sudo mkdir -p ~/.pip/</div><div class="line">sudo cat &lt;&lt; EOF &gt; ~/.pip/pip.conf</div><div class="line">[global]</div><div class="line">trusted-host=mirrors.aliyun.com</div><div class="line">index-url=http://mirrors.aliyun.com/pypi/simple/</div><div class="line">EOF</div><div class="line"></div><div class="line">sudo apt-get install libmysqlclient-dev -y</div><div class="line">ln <span class="_">-s</span> /home/usr/python36/bin/pip3 /usr/bin/pip36</div><div class="line">ln <span class="_">-s</span> /home/usr/python36/bin/python3 /usr/bin/python36</div></pre></td></tr></table></figure>
<p>以后就可以使用 <code>pip36</code>  <code>python36</code>来进行操作。</p>
<blockquote>
<p>如果在命令行中输入<code>scrapy</code>提示没这个命令，可以试试<code>python36 -m scrapy</code></p>
</blockquote>
]]></content>
    
    <summary type="html">
    
      &lt;pre&gt;&lt;code&gt;这是崔斯特的第四十四篇原创文章
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;linux操作  (๑• . •๑)&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/lJ8ygSI.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="linux" scheme="https://zhangslob.github.io/categories/linux/"/>
    
    
      <category term="linux" scheme="https://zhangslob.github.io/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>护眼神器了解下</title>
    <link href="https://zhangslob.github.io/2018/05/08/%E6%8A%A4%E7%9C%BC%E7%A5%9E%E5%99%A8%E4%BA%86%E8%A7%A3%E4%B8%8B/"/>
    <id>https://zhangslob.github.io/2018/05/08/护眼神器了解下/</id>
    <published>2018-05-08T14:05:24.000Z</published>
    <updated>2018-05-08T14:33:44.442Z</updated>
    
    <content type="html"><![CDATA[<pre><code>这是崔斯特的第四十三篇原创文章
</code></pre><p>保护眼睛  (๑• . •๑)</p>
<p><img src="http://p8eyj0cpn.bkt.clouddn.com/%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20180508221045.png" alt=""></p>
<a id="more"></a>
<p>整天面对屏幕，护眼是必须的，下面推荐几款小歪使用过的软件。</p>
<h1 id="flux"><a href="#flux" class="headerlink" title="flux"></a>flux</h1><p>官网：<a href="https://justgetflux.com/" target="_blank" rel="external">https://justgetflux.com/</a></p>
<p><img src="http://p8eyj0cpn.bkt.clouddn.com/%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20180508221449.png" alt=""></p>
<p>使用起来非常简单，是我之前非常喜欢的一款产品，会随着一天之内光线强弱改变屏幕的颜色。但是在linux上似乎不起作用，安装之后，屏幕颜色没有发生任何变化，于是我放弃了，选择另一款软件 ==</p>
<h1 id="redshift"><a href="#redshift" class="headerlink" title="redshift"></a>redshift</h1><p>网站：<a href="https://github.com/jonls/redshift" target="_blank" rel="external">https://github.com/jonls/redshift</a></p>
<p><img src="https://camo.githubusercontent.com/eb9522ffd5105488dcda49404e4c3107ffd88a1b/687474703a2f2f6a6f6e6c732e646b2f6173736574732f72656473686966742d69636f6e2d3235362e706e67" alt=""></p>
<p>Ubuntu下<code>sudo apt-get install redshift</code>就可以安装，打开方式是在命令行输入<code>redshift -v -t 4500:2500</code>，然后颜色就会变得非常舒服。</p>
<blockquote>
<p>如果在你的电脑上 redshift 有时不工作，检查是否开启了多个 redshift。</p>
</blockquote>
<h1 id="Safe-Eyes"><a href="#Safe-Eyes" class="headerlink" title="Safe Eyes"></a>Safe Eyes</h1><p>网站：<a href="http://slgobinath.github.io/SafeEyes/" target="_blank" rel="external">http://slgobinath.github.io/SafeEyes/</a></p>
<p><img src="https://slgobinath.github.io/SafeEyes/assets/screenshots/safeeyes_1.png" alt=""></p>
<p>这款应用会自动关闭屏幕，间隔一段时间会有休息，这个是否好好放松下自己的眼睛。</p>
<blockquote>
<p>这个好像只能安装在linux上</p>
</blockquote>
<p>大家还有什么推荐的呢？欢迎评论指出</p>
]]></content>
    
    <summary type="html">
    
      &lt;pre&gt;&lt;code&gt;这是崔斯特的第四十三篇原创文章
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;保护眼睛  (๑• . •๑)&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://p8eyj0cpn.bkt.clouddn.com/%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20180508221045.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="其他" scheme="https://zhangslob.github.io/categories/%E5%85%B6%E4%BB%96/"/>
    
    
      <category term="护眼" scheme="https://zhangslob.github.io/tags/%E6%8A%A4%E7%9C%BC/"/>
    
  </entry>
  
  <entry>
    <title>awesome_crawl(一)：腾讯新闻</title>
    <link href="https://zhangslob.github.io/2018/05/01/awesome-crawl-%E4%B8%80-%EF%BC%9A%E8%85%BE%E8%AE%AF%E6%96%B0%E9%97%BB/"/>
    <id>https://zhangslob.github.io/2018/05/01/awesome-crawl-一-：腾讯新闻/</id>
    <published>2018-05-01T13:52:11.000Z</published>
    <updated>2018-05-01T14:04:08.818Z</updated>
    
    <content type="html"><![CDATA[<pre><code>这是崔斯特的第四十二篇原创文章
</code></pre><p>awesome  (๑• . •๑)</p>
<p><img src="https://i.imgur.com/oDTELIM.png" alt=""></p>
<a id="more"></a>
<p>项目地址：<a href="https://github.com/zhangslob/awesome_crawl" target="_blank" rel="external">https://github.com/zhangslob/awesome_crawl</a></p>
<h1 id="awesome-crawl（优美的爬虫）"><a href="#awesome-crawl（优美的爬虫）" class="headerlink" title="awesome_crawl（优美的爬虫）"></a>awesome_crawl（优美的爬虫）</h1><h3 id="1、腾讯新闻的全站爬虫"><a href="#1、腾讯新闻的全站爬虫" class="headerlink" title="1、腾讯新闻的全站爬虫"></a><a href="https://github.com/zhangslob/awesome_crawl/tree/master/qq_news/qq_news" target="_blank" rel="external">1、腾讯新闻的全站爬虫</a></h3><p><strong>采集策略</strong></p>
<p>从<a href="http://www.qq.com/map/" target="_blank" rel="external">网站地图</a>出发，找出所有子分类，从每个子分类中再寻找详情页面的链接。</p>
<p>首先寻找每条新闻的ID，然后移动端采集具体内容。</p>
<p>再去找一些推荐新闻的接口，做一个“泛爬虫”。</p>
<p><strong>说明</strong></p>
<p>整套系统中分为两部分，一套是生产者，专门去采集qq新闻的链接，然后存放到redis中，一套是消费者，从redis中读取这些链接，解析详情数据。<br>所有配置文件都是爬虫中的<code>custom_settings</code>中，可以自定义。</p>
<p>如果需要设置代理，请在<code>middlewares.ProxyMiddleware</code>中设置。</p>
<p><strong>qq_list</strong>: 这个爬虫是生产者。运行之后，在你的redis服务器中会出现<code>qq_detail:start_urls</code>，即种子链接</p>
<p><strong>qq_detail</strong>: 这个爬虫是生消费者，运行之后会消费redis里面的数据，如下图：</p>
<p><img src="https://i.imgur.com/j81d8AP.png" alt=""></p>
<p>你可以自行添加更多爬虫去采集种子链接，如从<a href="http://www.qq.com/" target="_blank" rel="external">首页</a>进入匹配，从推荐入口：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> requests</div><div class="line"></div><div class="line">url = <span class="string">"https://pacaio.match.qq.com/xw/recommend"</span></div><div class="line"></div><div class="line">querystring = &#123;<span class="string">"num"</span>:<span class="string">"10^"</span>,<span class="string">"callback"</span>:<span class="string">"__jp0"</span>&#125;</div><div class="line"></div><div class="line">headers = &#123;</div><div class="line">    <span class="string">'accept-encoding'</span>: <span class="string">"gzip, deflate, br"</span>,</div><div class="line">    <span class="string">'accept-language'</span>: <span class="string">"zh-CN,zh;q=0.9,en;q=0.8"</span>,</div><div class="line">    <span class="string">'user-agent'</span>: <span class="string">"Mozilla/5.0 (iPhone; CPU iPhone OS 11_0 like Mac OS X) AppleWebKit/604.1.38 (KHTML, like Gecko) Version/11.0 Mobile/15A372 Safari/604.1"</span>,</div><div class="line">    <span class="string">'accept'</span>: <span class="string">"*/*"</span>,</div><div class="line">    <span class="string">'referer'</span>: <span class="string">"https://xw.qq.com/m/recommend/"</span>,</div><div class="line">    <span class="string">'authority'</span>: <span class="string">"pacaio.match.qq.com"</span>,</div><div class="line">    <span class="string">'cache-control'</span>: <span class="string">"no-cache"</span>,</div><div class="line">    &#125;</div><div class="line"></div><div class="line">response = requests.request(<span class="string">"GET"</span>, url, headers=headers, params=querystring)</div><div class="line"></div><div class="line">print(response.text)</div></pre></td></tr></table></figure>
<p>等等，你所需要做的仅仅是把这些抓到的种子链接塞到redis里面，也就是启用<code>qq_news.pipelines.RedisStartUrlsPipeline</code>这个中间件。</p>
<h2 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h2><ol>
<li>增加更多新闻链接的匹配，从推荐接口处获得更多种子链接</li>
<li>增加“泛爬虫”，采集种子链接</li>
<li>数据库字段检验</li>
<li>redis中数据为空爬虫自动关闭（目前redis数据被消费完之后爬虫并不会自动关闭，如下图）<br><img src="https://i.imgur.com/Sk4GDMA.png" alt=""></li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;pre&gt;&lt;code&gt;这是崔斯特的第四十二篇原创文章
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;awesome  (๑• . •๑)&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/oDTELIM.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="scrapy" scheme="https://zhangslob.github.io/categories/scrapy/"/>
    
    
      <category term="awesome_crawl" scheme="https://zhangslob.github.io/tags/awesome-crawl/"/>
    
      <category term="scrapy" scheme="https://zhangslob.github.io/tags/scrapy/"/>
    
  </entry>
  
  <entry>
    <title>scrapy-redis 和 scrapy 有什么区别？</title>
    <link href="https://zhangslob.github.io/2018/04/21/%E6%9C%89%E4%BB%80%E4%B9%88%E5%8C%BA%E5%88%AB%EF%BC%9F/"/>
    <id>https://zhangslob.github.io/2018/04/21/有什么区别？/</id>
    <published>2018-04-21T10:03:14.000Z</published>
    <updated>2018-04-21T10:09:16.779Z</updated>
    
    <content type="html"><![CDATA[<pre><code>这是崔斯特的第四十一篇原创文章
</code></pre><p>分布式爬虫  (๑• . •๑)</p>
<p><img src="https://i.imgur.com/1uic8Qk.jpg" alt=""></p>
<a id="more"></a>
<p>最近在工作中一直使用 <code>redis</code> 来管理分发爬虫任务，让我对 <code>scrapy-redis</code> 有很深刻的理解，下面让我慢慢说来。</p>
<blockquote>
<p>在所有的问题开始之前，要先有一个前提：你使用 <code>Scrapy</code> 框架做开发</p>
</blockquote>
<h1 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h1><p><code>scrapy-redis</code> 与 <code>Scrapy</code>的关系就像电脑与固态硬盘一样，是电脑中的一个插件，能让电脑更快的运行。</p>
<p><code>Scrapy</code> 是一个爬虫框架，<code>scrapy-redis</code> 则是这个框架上可以选择的插件，它可以让爬虫跑的更快。</p>
<h1 id="为什么使用-scrapy-redis"><a href="#为什么使用-scrapy-redis" class="headerlink" title="为什么使用 scrapy-redis"></a>为什么使用 <code>scrapy-redis</code></h1><p>首先，在实际开发中，我们总会对爬虫速度表示不满，为啥这么慢，能不能跑快点。除了爬虫本身的优化，我们就要引入<code>分布式爬虫</code>的概念。</p>
<p>我自己对<code>分布式爬虫</code>的理解就是：<strong>多个爬虫执行同一个任务</strong></p>
<blockquote>
<p>这里说下，<code>Scrapy</code>本身是不支持分布式的，因为它的任务管理和去重全部是在机器内存中实现的。</p>
</blockquote>
<p>在 <code>Scrapy</code> 中最出名的分布式插件就是<code>scrapy-redis</code>了，<code>scrapy-redis</code>的作用就是让你的爬虫快、更快、超级快。</p>
<h1 id="scrapy-redis-如何工作"><a href="#scrapy-redis-如何工作" class="headerlink" title="scrapy-redis 如何工作"></a><code>scrapy-redis</code> 如何工作</h1><p>最简单的方式是使用<code>redis</code>替换机器内存，那么具体如何操作呢？非常简单，你只需要在 <code>settings.py</code> 中加上三代码，就能让你的爬虫变为分布式。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">SCHEDULER = <span class="string">"scrapy_redis.scheduler.Scheduler"</span></div><div class="line"></div><div class="line">DUPEFILTER_CLASS = <span class="string">"scrapy_redis.dupefilter.RFPDupeFilter"</span></div><div class="line"></div><div class="line">REDIS_START_URLS_AS_SET = <span class="keyword">True</span></div></pre></td></tr></table></figure>
<p><code>SCHEDULER</code> 是任务分发与调度，把所有的爬虫开始的请求都放在redis里面，所有爬虫都去redis里面读取请求。<br><code>DUPEFILTER_CLASS</code> 是去重队列，负责所有请求的去重，<code>REDIS_START_URLS_AS_SET</code>指的是使用redis里面的set类型（简单完成去重），如果你没有设置，默认会选用list。</p>
<p>如果你现在运行你的爬虫，你可以在redis中看到出现了这两个key:</p>
<figure class="highlight avrasm"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="symbol">spider_name:</span>dupefilter</div><div class="line"><span class="symbol">spider_name:</span>requests</div></pre></td></tr></table></figure>
<p>格式是set，即不会有重复数据。前者就是redis的去重队列，对应<code>DUPEFILTER_CLASS</code>，后者是redis的请求调度，把里面的请求分发给爬虫，对应<code>SCHEDULER</code>。（里面的数据不会自动删除，如果你第二次跑，需要提前清空里面的数据）</p>
<h1 id="scrapy-redis-优点"><a href="#scrapy-redis-优点" class="headerlink" title="scrapy-redis 优点"></a><code>scrapy-redis</code> 优点</h1><h3 id="速度快"><a href="#速度快" class="headerlink" title="速度快"></a>速度快</h3><p><code>scrapy-redis</code> 使用redis这个速度非常快的非关系型（NoSQL）内存键值数据库，<strong>速度快</strong>是最重要原因（但是也会产生负面想过，下面会说到）。</p>
<p>为什么是<code>scrapy-redis</code>而不是<code>scrapy-mongo</code>呢，大家可以仔细想想。</p>
<h3 id="用法简单"><a href="#用法简单" class="headerlink" title="用法简单"></a>用法简单</h3><p>前人已经造好轮子了，<a href="https://github.com/rmax/scrapy-redis" target="_blank" rel="external">scrapy-redis</a>。<br>我们直接拿来用就好，而用法也像上面提到的在 <code>settings.py</code> 文件中配置。在文档中还有另一种用法，即<code>Feeding a Spider from Redis</code></p>
<ol>
<li>run the spider:<br><code>scrapy runspider myspider.py</code></li>
<li>push urls to redis:<br><code>redis-cli lpush myspider:start_urls http://google.com</code>（建议把<code>lpush</code>换为<code>zset</code>）</li>
</ol>
<p>其实这种用法就是先打开一个爬虫，他会一直在redis里面寻找key为 <code>myspider:start_urls</code>，如果存在，就提取里面的url。当然你也可以在爬虫中指定<code>redis_key</code>，默认的是爬虫的名字加上<code>:start_urls</code></p>
<h3 id="去重简单"><a href="#去重简单" class="headerlink" title="去重简单"></a>去重简单</h3><p>爬虫中去重是一件大事，使用了<code>scrapy-redis</code>后就很简单了。上面提到过使用redis的set类型就可以很容易达到这个目标了，即<code>REDIS_START_URLS_AS_SET = True</code>。</p>
<h1 id="scrapy-redis-缺点"><a href="#scrapy-redis-缺点" class="headerlink" title="scrapy-redis 缺点"></a><code>scrapy-redis</code> 缺点</h1><h3 id="内存问题"><a href="#内存问题" class="headerlink" title="内存问题"></a>内存问题</h3><p>为什么使用分布式爬虫，当然是因为会有很多链接需要跑，或者说会存放很多个<code>myspider:start_urls</code>到redis中，Redis是key-value数据库，面对key的内存搜索，优势明显，但是Redis吃的是纯内存，<code>myspider:start_urls</code>是一个有一个像<code>https://www.zhihu.com/people/cuishite</code>的链接，会占用大量的内存空间。之前就因为这个原因redis崩溃过无数次，那么如何优化？</p>
<p>网络上有的方法是 <a href="https://blog.csdn.net/bone_ace/article/details/53099042" target="_blank" rel="external"> scrapy_redis去重优化（已有7亿条数据），附Demo福利</a>，可以参考下。如果你有好的解决方法，欢迎私信告诉我。（保密原因就不介绍我们的处理方法了）</p>
<h3 id="Usage"><a href="#Usage" class="headerlink" title="Usage"></a>Usage</h3><p>这个其实不算做问题，只是官方文档上我觉得的小BUG，在这里 <a href="https://github.com/rmax/scrapy-redis#usage" target="_blank" rel="external">Usage</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Store scraped item in redis for post-processing.</span></div><div class="line">ITEM_PIPELINES = &#123;</div><div class="line">    <span class="string">'scrapy_redis.pipelines.RedisPipeline'</span>: <span class="number">300</span></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>Pipeline是这样写的<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">_process_item</span><span class="params">(self, item, spider)</span>:</span></div><div class="line">    key = self.item_key(item, spider)</div><div class="line">    data = self.serialize(item)</div><div class="line">    self.server.rpush(key, data)</div><div class="line">    <span class="keyword">return</span> item</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">item_key</span><span class="params">(self, item, spider)</span>:</span></div><div class="line">    <span class="string">"""Returns redis key based on given spider.</span></div><div class="line"></div><div class="line">    Override this function to use a different key depending on the item</div><div class="line">    and/or spider.</div><div class="line"></div><div class="line">    """</div><div class="line">    <span class="keyword">return</span> self.key % &#123;<span class="string">'spider'</span>: spider.name&#125;</div></pre></td></tr></table></figure></p>
<p>看不懂为什么要把数据储存在redis里面，这不又加大redis储存负担吗？对于新手来说真的不友好，或许可以考虑提一个pr。</p>
<h1 id="redis可视化工具"><a href="#redis可视化工具" class="headerlink" title="redis可视化工具"></a>redis可视化工具</h1><p>最后介绍两个redis可视化工具</p>
<ol>
<li><a href="https://github.com/uglide/RedisDesktopManager" target="_blank" rel="external">RedisDesktopManager</a> 比较出名的工具，但是经常会崩溃</li>
<li><a href="https://github.com/uniorder/kedis" target="_blank" rel="external">kedis</a> 国人开发的免费工具，这个界面还是可以的</li>
</ol>
<p><img src="https://camo.githubusercontent.com/de76115b295d30222fa0d6a1b79ffc9b31fb04e5/687474703a2f2f7777772e6b656861772e636f6d2f696d616765732f73637265656e73686f742e706e67" alt=""></p>
]]></content>
    
    <summary type="html">
    
      &lt;pre&gt;&lt;code&gt;这是崔斯特的第四十一篇原创文章
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;分布式爬虫  (๑• . •๑)&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/1uic8Qk.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="scrapy" scheme="https://zhangslob.github.io/categories/scrapy/"/>
    
    
      <category term="爬虫" scheme="https://zhangslob.github.io/tags/%E7%88%AC%E8%99%AB/"/>
    
      <category term="scrapy" scheme="https://zhangslob.github.io/tags/scrapy/"/>
    
  </entry>
  
  <entry>
    <title>来codewars与我一起玩耍吧</title>
    <link href="https://zhangslob.github.io/2018/04/12/%E6%9D%A5codewars%E4%B8%8E%E6%88%91%E4%B8%80%E8%B5%B7%E7%8E%A9%E8%80%8D%E5%90%A7/"/>
    <id>https://zhangslob.github.io/2018/04/12/来codewars与我一起玩耍吧/</id>
    <published>2018-04-12T13:25:13.000Z</published>
    <updated>2018-04-12T14:08:23.122Z</updated>
    
    <content type="html"><![CDATA[<pre><code>这是崔斯特的第四十篇原创文章
</code></pre><p>并肩作战  (๑• . •๑)</p>
<p><img src="https://i.imgur.com/tyYtQ02.jpg" alt=""></p>
<a id="more"></a>
<h1 id="先看一道题目"><a href="#先看一道题目" class="headerlink" title="先看一道题目"></a>先看一道题目</h1><p>如何使用代码表示“石头、剪刀、布”之间的关系。</p>
<blockquote>
<p>即：石头 &gt; 剪刀，剪刀 &gt; 布， 剪刀 &gt; 布</p>
</blockquote>
<p>当时我想了很多，构造一个字典，和数字对应，但是应该如何表示“大小”关系呢？想破脑袋都想不出来，最后看了答案，形如</p>
<p><code>dict = {&#39;a&#39;: &#39;b&#39;, &#39;b&#39;: &#39;c&#39;, &#39;c&#39;: &#39;a&#39;}</code></p>
<p>简直是妙啊！！！</p>
<p>原题在这里，<a href="https://www.codewars.com/kata/5672a98bdbdd995fad00000f" target="_blank" rel="external">Rock Paper Scissors!</a>，可以自己试试看。</p>
<p>我觉得很妙的解法</p>
<h1 id="CodeWars"><a href="#CodeWars" class="headerlink" title="CodeWars"></a>CodeWars</h1><p>这是CodeWars上的一题，我觉得挺有意思的。CodeWars其实和leetcode差不多，但是我更喜欢有这几点。</p>
<h2 id="界面"><a href="#界面" class="headerlink" title="界面"></a>界面</h2><p><img src="https://i.imgur.com/iJDJEyh.png" alt=""></p>
<p>看着挺舒服的，同时提供了测试代码。</p>
<h2 id="够简单"><a href="#够简单" class="headerlink" title="够简单"></a>够简单</h2><p>真的，CodeWars上有些题目真的很简单，适合我这种新手，哈哈，比如：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Complete the solution so that it reverses the string value passed into it.</span></div><div class="line"><span class="comment">#</span></div><div class="line"><span class="comment"># solution('world') # returns 'dlrow'</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">solution</span><span class="params">(string)</span>:</span></div><div class="line">    <span class="keyword">return</span> string[::<span class="number">-1</span>]</div></pre></td></tr></table></figure>
<p><img src="https://i.imgur.com/76PQr2I.png" alt=""></p>
<p>还可以选择问题类型。</p>
<h2 id="可以自己出题，还可以邀请队友"><a href="#可以自己出题，还可以邀请队友" class="headerlink" title="可以自己出题，还可以邀请队友"></a>可以自己出题，还可以邀请队友</h2><p><a href="www.codewars.com/r/UsAiUQ">www.codewars.com/r/UsAiUQ</a><br><a href="www.codewars.com/r/UsAiUQ">codewars</a> 点一下，就可以成为我的盟友。</p>
<p><img src="https://i.imgur.com/MGFfIiV.jpg" alt=""></p>
<p>点一下，玩一年，装逼不花一分钱！</p>
<h2 id="可以上榜"><a href="#可以上榜" class="headerlink" title="可以上榜"></a>可以上榜</h2><p><a href="https://www.codewars.com/users/leaderboard" target="_blank" rel="external">leaderboard</a></p>
<p><img src="https://i.imgur.com/BsP8kJP.png" alt=""></p>
<p>第二名竟然是国人唉，不知是哪位大佬。希望有更多中国人可以出现在上面。</p>
<h1 id="后话"><a href="#后话" class="headerlink" title="后话"></a>后话</h1><p>目前我也还是一个萌新，希望大佬能带带我。</p>
<p>我在Github上开了一个仓库，<a href="https://github.com/zhangslob/codewars_python" target="_blank" rel="external">codewars_python</a> 里面都是用 python的解题方法，但是现在还只有几题而已，希望大家可以一起来参与，多提pr。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># -*- coding: utf-8 -*-</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># ATM machines allow 4 or 6 digit PIN codes and PIN codes cannot contain anything but exactly 4 digits or exactly 6 digits.</span></div><div class="line"></div><div class="line"><span class="comment"># If the function is passed a valid PIN string, return true, else return false.</span></div><div class="line"></div><div class="line"><span class="comment"># eg:</span></div><div class="line"></div><div class="line"><span class="comment"># validate_pin("1234") == True</span></div><div class="line"><span class="comment"># validate_pin("12345") == False</span></div><div class="line"><span class="comment"># validate_pin("a234") == False</span></div><div class="line"></div><div class="line"><span class="comment"># My Solutiuon</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">validate_pin</span><span class="params">(pin)</span>:</span></div><div class="line">    <span class="comment">#return true or false</span></div><div class="line">    <span class="keyword">return</span> pin.isdigit() <span class="keyword">if</span> len(pin) == <span class="number">4</span> <span class="keyword">or</span> len(pin) == <span class="number">6</span> <span class="keyword">else</span> <span class="keyword">False</span></div><div class="line"></div><div class="line"> <span class="comment"># Wonderful Solutiuon</span></div><div class="line"></div><div class="line"> <span class="function"><span class="keyword">def</span> <span class="title">validate_pin</span><span class="params">(pin)</span>:</span></div><div class="line">    <span class="keyword">return</span> len(pin) <span class="keyword">in</span> (<span class="number">4</span>, <span class="number">6</span>) <span class="keyword">and</span> pin.isdigit()</div></pre></td></tr></table></figure>
]]></content>
    
    <summary type="html">
    
      &lt;pre&gt;&lt;code&gt;这是崔斯特的第四十篇原创文章
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;并肩作战  (๑• . •๑)&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/tyYtQ02.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="算法" scheme="https://zhangslob.github.io/categories/%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="算法" scheme="https://zhangslob.github.io/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="codewars" scheme="https://zhangslob.github.io/tags/codewars/"/>
    
  </entry>
  
  <entry>
    <title>Scrapy中如何提高数据的插入速度</title>
    <link href="https://zhangslob.github.io/2018/03/28/Scrapy%E4%B8%AD%E5%A6%82%E4%BD%95%E6%8F%90%E9%AB%98%E6%95%B0%E6%8D%AE%E7%9A%84%E6%8F%92%E5%85%A5%E9%80%9F%E5%BA%A6/"/>
    <id>https://zhangslob.github.io/2018/03/28/Scrapy中如何提高数据的插入速度/</id>
    <published>2018-03-28T13:18:32.000Z</published>
    <updated>2018-03-28T13:34:51.830Z</updated>
    
    <content type="html"><![CDATA[<pre><code>这是崔斯特的第三十九篇原创文章
</code></pre><p>长期更新  (๑• . •๑)</p>
<p><img src="https://i.imgur.com/ThJm8v5.jpg" alt=""></p>
<a id="more"></a>
<h1 id="速度问题"><a href="#速度问题" class="headerlink" title="速度问题"></a>速度问题</h1><p>最近工作中遇到这么一个问题，全站抓取时采用分布式：爬虫A与爬虫B，爬虫A给爬虫B<code>喂饼</code>，爬虫B由于各种原因<code>运行</code>的比较慢，达不到预期效果，所以必须对爬虫B进行优化。</p>
<p>提升Scrapy运行速度有很多方法，国外有大佬说过</p>
<p><a href="https://stackoverflow.com/questions/17029752/speed-up-web-scraper" target="_blank" rel="external">Speed up web scraper
</a></p>
<p>Here’s a collection of things to try:</p>
<ol>
<li>use latest scrapy version (if not using already)</li>
<li>check if non-standard middlewares are used</li>
<li>try to increase CONCURRENT_REQUESTS_PER_DOMAIN, CONCURRENT_REQUESTS settings (docs)<br>turn off logging LOG_ENABLED = False (docs)</li>
<li>try yielding an item in a loop instead of collecting items into the items list and returning them<br>use local cache DNS (see this thread)</li>
<li>check if this site is using download threshold and limits your download speed (see this thread)<br>log cpu and memory usage during the spider run - see if there are any problems there</li>
<li>try run the same spider under scrapyd service</li>
<li>see if grequests + lxml will perform better (ask if you need any help with implementing this solution)</li>
<li>try running Scrapy on pypy, see Running Scrapy on PyPy</li>
</ol>
<p>大致看了下，确实可以提高爬虫运行速度，但是对于海量数据（这里说的是百万级）还需要考虑一点的就是数据插入问题，这里我们使用的是 Mongo。</p>
<h1 id="官方示例"><a href="#官方示例" class="headerlink" title="官方示例"></a>官方示例</h1><p>让我们先从官方文档开始 <a href="http://scrapy.readthedocs.io/en/latest/topics/item-pipeline.html#write-items-to-mongodb" target="_blank" rel="external">Write items to MongoDB</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> pymongo</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">MongoPipeline</span><span class="params">(object)</span>:</span></div><div class="line"></div><div class="line">    collection_name = <span class="string">'scrapy_items'</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, mongo_uri, mongo_db)</span>:</span></div><div class="line">        self.mongo_uri = mongo_uri</div><div class="line">        self.mongo_db = mongo_db</div><div class="line"></div><div class="line"><span class="meta">    @classmethod</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">from_crawler</span><span class="params">(cls, crawler)</span>:</span></div><div class="line">        <span class="keyword">return</span> cls(</div><div class="line">            mongo_uri=crawler.settings.get(<span class="string">'MONGO_URI'</span>),</div><div class="line">            mongo_db=crawler.settings.get(<span class="string">'MONGO_DATABASE'</span>, <span class="string">'items'</span>)</div><div class="line">        )</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">open_spider</span><span class="params">(self, spider)</span>:</span></div><div class="line">        self.client = pymongo.MongoClient(self.mongo_uri)</div><div class="line">        self.db = self.client[self.mongo_db]</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close_spider</span><span class="params">(self, spider)</span>:</span></div><div class="line">        self.client.close()</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self, item, spider)</span>:</span></div><div class="line">        self.db[self.collection_name].insert_one(dict(item))</div><div class="line">        <span class="keyword">return</span> item</div></pre></td></tr></table></figure>
<p>比较简单，这里插入使用的方法是 <code>insert_one</code>，继续文档：</p>
<p><code>insert_one(document, bypass_document_validation=False, session=None)</code></p>
<p>Insert a single document.<br><figure class="highlight cmd"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">&gt;&gt;&gt; db.test.count(&#123;'x': <span class="number">1</span>&#125;)</div><div class="line"><span class="number">0</span></div><div class="line">&gt;&gt;&gt; result = db.test.insert_one(&#123;'x': <span class="number">1</span>&#125;)</div><div class="line">&gt;&gt;&gt; result.inserted_id</div><div class="line">ObjectId('<span class="number">54</span>f112defba522406c9cc208')</div><div class="line">&gt;&gt;&gt; db.test.find_one(&#123;'x': <span class="number">1</span>&#125;)</div><div class="line">&#123;u'x': <span class="number">1</span>, u'_id': ObjectId('<span class="number">54</span>f112defba522406c9cc208')&#125;</div></pre></td></tr></table></figure></p>
<p>以前经常使用的 <code>insert</code> 方法，已经不被赞同</p>
<p><code>insert(doc_or_docs, manipulate=True, check_keys=True, continue_on_error=False, **kwargs)</code></p>
<p>Insert a document(s) into this collection.<br><figure class="highlight cmd"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">DEPRECATED - Use insert_one() or insert_many() instead.</div><div class="line"></div><div class="line">Changed <span class="keyword">in</span> version <span class="number">3</span>.<span class="number">0</span>: Removed the safe parameter. Pass w=<span class="number">0</span> <span class="keyword">for</span> unacknowledged write operations.</div></pre></td></tr></table></figure></p>
<p><code>insert</code> 简单理解就是插入，把我们采集到的 <code>item</code> 插入到数据库，这样存在一个很严重的问题，就是<strong>去重</strong></p>
<h1 id="去重"><a href="#去重" class="headerlink" title="去重"></a>去重</h1><p>晚上有一种很流行的写法，使用 <code>update</code>命令，如：</p>
<p><code>self.db[self.collection_name].update({&#39;id&#39;: item[&#39;id&#39;]}, {&#39;$set&#39;: dict(item)}, True)</code></p>
<p>解释为：</p>
<blockquote>
<p>比较重要的一点就在于process_item，在这里使用了update方法，第一个参数传入查询条件，这里使用的是id，第二个参数传入字典类型的对象，就是我们的item，第三个参数传入True，这样就可以保证，如果查询数据存在的话就更新，不存在的话就插入。这样就可以保证去重了。</p>
</blockquote>
<p>这确实是一种很简单的方法，其实原理很简单，就是在每次插入数据前，对数据库中查询，是否有该 ID，如果没有就插入，如果有就放弃。</p>
<p>对于数据量比较少的项目，这确实是一种很简单的方法，很简单就完成了目标。</p>
<p>但是，我们现在说的是百万级数据，如果每一条数据在插入前，都需要去查询该数据是否在数据库，那会多么耗时，效率会大大较低，那么还有什么好办法呢？</p>
<h1 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h1><h3 id="MongoDB-索引"><a href="#MongoDB-索引" class="headerlink" title="MongoDB 索引"></a>MongoDB 索引</h3><p>索引能够实现高效地查询。没有索引，MongoDB 就必须扫描集合中的所有文档，才能找到匹配查询语句的文档。这种扫描毫无效率可言，需要处理大量的数据。</p>
<p>索引是一种特殊的数据结构，将一小块数据集保存为容易遍历的形式。索引能够存储某种特殊字段或字段集的值，并按照索引指定的方式将字段值进行排序。</p>
<p>我们可以借助索引，使用 <code>insert_one</code>方法提高效率。代码实现：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">MongoDBPipeline</span><span class="params">(object)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">open_spider</span><span class="params">(self, spider)</span>:</span></div><div class="line">        self.client = mongodb_client</div><div class="line">        self.db = self.client.get_database()</div><div class="line">        self.collection = self.db[<span class="string">'test'</span>]</div><div class="line">        <span class="comment"># 添加唯一索引</span></div><div class="line">        self.collection.create_index(<span class="string">'id'</span>, unique=<span class="keyword">True</span>)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close_spider</span><span class="params">(self, spider)</span>:</span></div><div class="line">        self.client.close()</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self, item, spider)</span>:</span></div><div class="line">        <span class="keyword">try</span>:</div><div class="line">            self.collection.insert_one(dict(item))</div><div class="line">            <span class="keyword">return</span> item</div><div class="line">        <span class="keyword">except</span> DuplicateKeyError:</div><div class="line">            spider.logger.debug(<span class="string">' duplicate key error collection'</span>)</div><div class="line">            <span class="keyword">return</span> item</div></pre></td></tr></table></figure>
<p>其实很简单，就是在 <code>open_spider</code>先创建唯一索引，然后再插入数据。注意需要在<code>process_item</code>中使用异常处理，因为很有可能插入重复数据，到时候就会输出日志。</p>
<h3 id="其他方法"><a href="#其他方法" class="headerlink" title="其他方法"></a>其他方法</h3><p>mongo 除了 <code>insert_one</code>方法还有一种，<code>insert_many</code></p>
<p><code>insert_many(documents, ordered=True, bypass_document_validation=False, session=None)</code></p>
<p>Insert an iterable of documents.<br><figure class="highlight cmd"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">&gt;&gt;&gt; db.test.count()</div><div class="line"><span class="number">0</span></div><div class="line">&gt;&gt;&gt; result = db.test.insert_many([&#123;'x': i&#125; <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">2</span>)])</div><div class="line">&gt;&gt;&gt; result.inserted_ids</div><div class="line">[ObjectId('<span class="number">54</span>f113fffba522406c9cc20e'), ObjectId('<span class="number">54</span>f113fffba522406c9cc20f')]</div><div class="line">&gt;&gt;&gt; db.test.count()</div><div class="line"><span class="number">2</span></div></pre></td></tr></table></figure></p>
<p>这样插入的数据不再是一条，而是很多，</p>
<p><a href="https://stackoverflow.com/questions/36792649/whats-the-difference-between-insert-insertone-and-insertmany-method" target="_blank" rel="external">What’s the difference between insert(), insertOne() and insertMany() methods on MongoDB</a></p>
<p>大佬有写到，可以去看看。</p>
<p>同时插入多条数据，减轻数据库压力。但是这个“多”到底还是多少，目前不得而知。</p>
<h1 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h1><p>除了更多机器和更多节点，还有很多方法可以提升 <code>Scrapy</code>运行速度。</p>
<p>今天说到的是管道阻塞问题，还有其他地方也可以优化，还需要努力。</p>
<p><img src="https://i.imgur.com/SQrGHds.png" alt=""></p>
]]></content>
    
    <summary type="html">
    
      &lt;pre&gt;&lt;code&gt;这是崔斯特的第三十九篇原创文章
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;长期更新  (๑• . •๑)&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/ThJm8v5.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Scrapy" scheme="https://zhangslob.github.io/categories/Scrapy/"/>
    
    
      <category term="爬虫" scheme="https://zhangslob.github.io/tags/%E7%88%AC%E8%99%AB/"/>
    
      <category term="Scrapy" scheme="https://zhangslob.github.io/tags/Scrapy/"/>
    
  </entry>
  
  <entry>
    <title>Hi，这里是我的爬虫笔记</title>
    <link href="https://zhangslob.github.io/2018/03/25/Hi%EF%BC%8C%E8%BF%99%E9%87%8C%E6%98%AF%E6%88%91%E7%9A%84%E7%88%AC%E8%99%AB%E7%AC%94%E8%AE%B0/"/>
    <id>https://zhangslob.github.io/2018/03/25/Hi，这里是我的爬虫笔记/</id>
    <published>2018-03-25T13:37:15.000Z</published>
    <updated>2018-03-25T14:41:17.359Z</updated>
    
    <content type="html"><![CDATA[<pre><code>这是崔斯特的第三十八篇原创文章
</code></pre><p>长期更新  (๑• . •๑)</p>
<p><img src="https://i.imgur.com/St35Zmv.jpg" alt=""></p>
<a id="more"></a>
<p>平时有个习惯，会把自己的笔记写在有道云里面，现在做个整理。会长期更新，因为我是BUG制造机。</p>
<h1 id="解析"><a href="#解析" class="headerlink" title="解析"></a>解析</h1><h2 id="xpath提取所有节点文本"><a href="#xpath提取所有节点文本" class="headerlink" title="xpath提取所有节点文本"></a>xpath提取所有节点文本</h2><figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">"test3"</span>&gt;</span>我左青龙，<span class="tag">&lt;<span class="name">span</span> <span class="attr">id</span>=<span class="string">"tiger"</span>&gt;</span>右白虎，<span class="tag">&lt;<span class="name">ul</span>&gt;</span>上朱雀，<span class="tag">&lt;<span class="name">li</span>&gt;</span>下玄武。<span class="tag">&lt;/<span class="name">li</span>&gt;</span><span class="tag">&lt;/<span class="name">ul</span>&gt;</span>老牛在当中，<span class="tag">&lt;/<span class="name">span</span>&gt;</span>龙头在胸口。<span class="tag">&lt;<span class="name">div</span>&gt;</span></div></pre></td></tr></table></figure>
<p>使用xpath的string(.)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#!/usr/bin/env python</span></div><div class="line"><span class="comment"># -*- coding: utf-8 -*-</span></div><div class="line"></div><div class="line"><span class="keyword">from</span> scrapy.selector <span class="keyword">import</span> Selector</div><div class="line"></div><div class="line">text = <span class="string">'&lt;div id="test3"&gt;我左青龙，&lt;span id="tiger"&gt;右白虎，&lt;ul&gt;上朱雀，&lt;li&gt;下玄武。&lt;/li&gt;&lt;/ul&gt;老牛在当中，&lt;/span&gt;龙头在胸口。&lt;div&gt;'</span></div><div class="line">s = Selector(text=text)</div><div class="line">data = s.xpath(<span class="string">'//div[@id="test3"]'</span>)</div><div class="line">info = data.xpath(<span class="string">'string(.)'</span>).extract()[<span class="number">0</span>]</div><div class="line">print(info)</div><div class="line"></div><div class="line"><span class="comment"># output: 我左青龙，右白虎，上朱雀，下玄武。老牛在当中，龙头在胸口。</span></div></pre></td></tr></table></figure>
<h2 id="如何解决详情页面元素改变"><a href="#如何解决详情页面元素改变" class="headerlink" title="如何解决详情页面元素改变"></a>如何解决详情页面元素改变</h2><p>这个问题是这样产生的，在很多PC站，比如链家，这个页面有这些字段A，但是下个页面这个字段A没了，取而代之的是字段B，在xpath定位时就失效了。这个问题很常见，大体思路是这样的。</p>
<ol>
<li>创建一个包含所有字段的dict: <code>data = {}.fromkeys((&#39;url&#39;, &#39;price&#39;, &#39;address&#39;))</code></li>
<li>然后根据网页中是否有字段来取值，例如，有’url’就取对应的value，没有则为空</li>
<li>这样就可以完美解决匹配不全问题</li>
</ol>
<h1 id="Scrapy-相关"><a href="#Scrapy-相关" class="headerlink" title="Scrapy 相关"></a>Scrapy 相关</h1><h2 id="文件编写"><a href="#文件编写" class="headerlink" title="文件编写"></a>文件编写</h2><p>逻辑文件和解析部分分开写，匹配文件目录是<code>utils/parse/</code>，爬虫文件目录是<code>spiders/</code></p>
<h2 id="Scrapy-中文乱码"><a href="#Scrapy-中文乱码" class="headerlink" title="Scrapy 中文乱码"></a>Scrapy 中文乱码</h2><p>在 <code>setting</code> 文件中设置：<code>FEED_EXPORT_ENCODING = &#39;utf-8&#39;</code></p>
<h2 id="Scrapy-使用Mongo"><a href="#Scrapy-使用Mongo" class="headerlink" title="Scrapy 使用Mongo"></a>Scrapy 使用Mongo</h2><p><code>pipelines.py</code></p>
<ol>
<li>首先我们要从settings文件中读取数据的地址、端口、数据库名称。</li>
<li>拿到数据库的基本信息后进行连接。</li>
<li>将数据写入数据库（update制定唯一键）</li>
<li>关闭数据库</li>
</ol>
<blockquote>
<p>注意：只有打开和关闭是只执行一次，而写入操作会根据具体的写入次数而定。<br>Redis 无需关闭<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> pymongo</div><div class="line"> </div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">MongoDBPipeline</span><span class="params">(object)</span>:</span></div><div class="line">    <span class="string">"""</span></div><div class="line">    1、连接数据库操作</div><div class="line">    """</div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,mongourl,mongoport,mongodb)</span>:</span></div><div class="line">        <span class="string">'''</span></div><div class="line">        初始化mongodb数据的url、端口号、数据库名称</div><div class="line">        :param mongourl:</div><div class="line">        :param mongoport:</div><div class="line">        :param mongodb:</div><div class="line">        '''</div><div class="line">        self.mongourl = mongourl</div><div class="line">        self.mongoport = mongoport</div><div class="line">        self.mongodb = mongodb</div><div class="line"> </div><div class="line"><span class="meta">    @classmethod</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">from_crawler</span><span class="params">(cls,crawler)</span>:</span></div><div class="line">        <span class="string">"""</span></div><div class="line">        1、读取settings里面的mongodb数据的url、port、DB。</div><div class="line">        :param crawler:</div><div class="line">        :return:</div><div class="line">        """</div><div class="line">        <span class="keyword">return</span> cls(</div><div class="line">            mongourl = crawler.settings.get(<span class="string">"MONGO_URL"</span>),</div><div class="line">            mongoport = crawler.settings.get(<span class="string">"MONGO_PORT"</span>),</div><div class="line">            mongodb = crawler.settings.get(<span class="string">"MONGO_DB"</span>)</div><div class="line">        )</div><div class="line"> </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">open_spider</span><span class="params">(self,spider)</span>:</span></div><div class="line">        <span class="string">'''</span></div><div class="line">        1、连接mongodb数据</div><div class="line">        :param spider:</div><div class="line">        :return:</div><div class="line">        '''</div><div class="line">        self.client = pymongo.MongoClient(self.mongourl,self.mongoport)</div><div class="line">        self.db = self.client[self.mongodb]</div><div class="line"> </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self,item,spider)</span>:</span></div><div class="line">        <span class="string">'''</span></div><div class="line">        1、将数据写入数据库</div><div class="line">        :param item:</div><div class="line">        :param spider:</div><div class="line">        :return:</div><div class="line">        '''</div><div class="line">        name = item.__class__.__name__</div><div class="line">        <span class="comment"># self.db[name].insert(dict(item))</span></div><div class="line">        self.db[<span class="string">'user'</span>].update(&#123;<span class="string">'url_token'</span>:item[<span class="string">'url_token'</span>]&#125;,&#123;<span class="string">'$set'</span>:item&#125;,<span class="keyword">True</span>)</div><div class="line">        <span class="keyword">return</span> item</div><div class="line"> </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close_spider</span><span class="params">(self,spider)</span>:</span></div><div class="line">        <span class="string">'''</span></div><div class="line">        1、关闭数据库连接</div><div class="line">        :param spider:</div><div class="line">        :return:</div><div class="line">        '''</div><div class="line">        self.client.close()</div></pre></td></tr></table></figure></p>
</blockquote>
<h2 id="scrapy图片下载"><a href="#scrapy图片下载" class="headerlink" title="scrapy图片下载"></a>scrapy图片下载</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> scrapy</div><div class="line"><span class="keyword">from</span> scrapy.pipelines.images <span class="keyword">import</span> ImagesPipeline</div><div class="line"><span class="keyword">from</span> scrapy.exceptions <span class="keyword">import</span> DropItem</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyImagesPipeline</span><span class="params">(ImagesPipeline)</span>:</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_media_requests</span><span class="params">(self, item, info)</span>:</span></div><div class="line">        <span class="keyword">for</span> image_url <span class="keyword">in</span> item[<span class="string">'image_urls'</span>]:</div><div class="line">            <span class="keyword">yield</span> scrapy.Request(image_url)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">item_completed</span><span class="params">(self, results, item, info)</span>:</span></div><div class="line">        image_paths = [x[<span class="string">'path'</span>] <span class="keyword">for</span> ok, x <span class="keyword">in</span> results <span class="keyword">if</span> ok]</div><div class="line">        <span class="keyword">if</span> <span class="keyword">not</span> image_paths:</div><div class="line">            <span class="keyword">raise</span> DropItem(<span class="string">"Item contains no images"</span>)</div><div class="line">        item[<span class="string">'image_paths'</span>] = image_paths</div><div class="line">        <span class="keyword">return</span> item</div></pre></td></tr></table></figure>
<h2 id="scrapy-暂停爬虫"><a href="#scrapy-暂停爬虫" class="headerlink" title="scrapy 暂停爬虫"></a>scrapy 暂停爬虫</h2><p><code>scrapy crawl somespider -s JOBDIR=crawls/somespider-1</code></p>
<h2 id="scrapy-redis-分布式"><a href="#scrapy-redis-分布式" class="headerlink" title="scrapy_redis 分布式"></a>scrapy_redis 分布式</h2><p>使用队列与去重即可完成分布式需求，需要注意的是 Redis 格式，默认采用的是 <code>list</code>， 可以在 <code>settings.py</code> 文件中设置 <code>REDIS_START_URLS_AS_SET = True</code>，使用 <code>Redis</code>的 <code>set</code>类型（去重种子链接）</p>
<h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><h2 id="超时问题"><a href="#超时问题" class="headerlink" title="超时问题"></a>超时问题</h2><p>自定义超时时间</p>
<p><code>sudo pip3 --default-timeout=100 install -U scrapy</code></p>
<p>或者 使用其他源</p>
<p><code>sudo pip3 install scrapy -i https://pypi.tuna.tsinghua.edu.cn/simple</code></p>
<h2 id="权限问题"><a href="#权限问题" class="headerlink" title="权限问题"></a>权限问题</h2><p>安装某模块时，报错：<code>PermissionError: [WinError 5] 拒绝访问。: &#39;c:\\program files\\python35\\Lib\\sit
e-packages\\lxml&#39;</code></p>
<p>最简单方法：<code>pip install --user lxml</code></p>
<h1 id="Pycharm-相关"><a href="#Pycharm-相关" class="headerlink" title="Pycharm 相关"></a>Pycharm 相关</h1><h2 id="gitignore-文件"><a href="#gitignore-文件" class="headerlink" title=".gitignore 文件"></a>.gitignore 文件</h2><p>安装插件： <code>Preferences &gt; Plugins &gt; Browse repositories... &gt; Search for &quot;.ignore&quot; &gt; Install Plugin</code></p>
<p>然后就可以很方便的添加到 .gitignore </p>
<p><img src="https://i.imgur.com/ZvPCFIV.png" alt=""></p>
<h2 id="显示函数"><a href="#显示函数" class="headerlink" title="显示函数"></a>显示函数</h2><p><img src="https://i.imgur.com/iLhj1d9.png" alt=""></p>
<p>点击 <code>Show Members</code>，查看目录，会显示相应的类和函数</p>
<h2 id="激活码"><a href="#激活码" class="headerlink" title="激活码"></a>激活码</h2><ol>
<li><a href="http://idea.liyang.io" target="_blank" rel="external">http://idea.liyang.io</a></li>
<li><a href="http://xidea.online" target="_blank" rel="external">http://xidea.online</a></li>
</ol>
<h1 id="数据"><a href="#数据" class="headerlink" title="数据"></a>数据</h1><h2 id="Mongo导出命令"><a href="#Mongo导出命令" class="headerlink" title="Mongo导出命令"></a>Mongo导出命令</h2><p><code>λ mongoexport -d test -c set --type=csv -f name,age -o set.csv</code></p>
<p><code>λ mongoexport -h 10.10.10.11 -d test -c test --type=csv -f url,id,title -o data.csv</code></p>
<h1 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h1><h2 id="requirements-txt-文件"><a href="#requirements-txt-文件" class="headerlink" title="requirements.txt 文件"></a>requirements.txt 文件</h2><p>小提示：使用 <a href="https://github.com/damnever/pigar" target="_blank" rel="external">pigar</a> 可以一键生成 requirements.txt 文件</p>
<p>Installation：<code>pip install pigar</code></p>
<p>Usage：<code>pigar</code> </p>
<p><img src="https://raw.githubusercontent.com/Damnever/pigar/master/short-guide.gif" alt=""></p>
<p>好了，今天先写这点，以后再补上。</p>
<p><img src="https://i.imgur.com/e4InMl7.jpg" alt=""></p>
]]></content>
    
    <summary type="html">
    
      &lt;pre&gt;&lt;code&gt;这是崔斯特的第三十八篇原创文章
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;长期更新  (๑• . •๑)&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/St35Zmv.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="爬虫" scheme="https://zhangslob.github.io/categories/%E7%88%AC%E8%99%AB/"/>
    
    
      <category term="爬虫" scheme="https://zhangslob.github.io/tags/%E7%88%AC%E8%99%AB/"/>
    
  </entry>
  
  <entry>
    <title>学习Git（二）基本操作</title>
    <link href="https://zhangslob.github.io/2018/03/19/%E5%AD%A6%E4%B9%A0Git%EF%BC%88%E4%BA%8C%EF%BC%89%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/"/>
    <id>https://zhangslob.github.io/2018/03/19/学习Git（二）基本操作/</id>
    <published>2018-03-19T13:11:39.000Z</published>
    <updated>2018-03-19T14:46:11.372Z</updated>
    
    <content type="html"><![CDATA[<pre><code>这是崔斯特的第三十七篇原创文章
</code></pre><p>继续补基础  (๑• . •๑)</p>
<p><img src="https://i.imgur.com/nSjj0lk.png" alt=""></p>
<a id="more"></a>
<h1 id="Git-基础操作"><a href="#Git-基础操作" class="headerlink" title="Git 基础操作"></a>Git 基础操作</h1><h2 id="1-创建版本库"><a href="#1-创建版本库" class="headerlink" title="1. 创建版本库"></a>1. 创建版本库</h2><p>什么是版本库呢？版本库又名仓库，英文名 repository，你可以简单理解成一个目录，这个目录里面的所有文件都可以被 Git 管理起来，每个文件的修改、删除，Git 都能跟踪，以便任何时刻都可以追踪历史，或者在将来某个时刻可以“还原”。</p>
<p>所以，创建一个版本库非常简单，首先，选择一个合适的地方，创建一个空目录：</p>
<figure class="highlight elixir"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="variable">$ </span>mkdir learngit</div><div class="line"><span class="variable">$ </span>cd learngit</div><div class="line"><span class="variable">$ </span>pwd</div><div class="line">/Users/learngit</div></pre></td></tr></table></figure>
<p><code>pwd</code>命令用于显示当前目录。</p>
<p>如果你使用 Windows 系统，为了避免遇到各种莫名其妙的问题，请确保目录名（包括父目录）不包含中文。</p>
<p>第二步，通过<code>git init</code>命令把这个目录变成 Git 可以管理的仓库：</p>
<figure class="highlight awk"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ git init</div><div class="line">Initialized empty Git repository <span class="keyword">in</span> <span class="regexp">/Users/</span>learngit<span class="regexp">/.git/</span></div></pre></td></tr></table></figure>
<p>瞬间 Git 就把仓库建好了，而且告诉你是一个空的仓库（empty Git repository）</p>
<p>用<code>ls -ah</code>命令就可以看见当前目录下多了一个<code>.git</code>的目录，这个目录是 Git 来跟踪管理版本库的，没事千万不要手动修改这个目录里面的文件，不然改乱了，就把 Git 仓库给破坏了。</p>
<p>一定要放到 learngit 目录下或子目录下</p>
<figure class="highlight elixir"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="variable">$ </span>git status <span class="comment"># 随时用git status 查看文件状态</span></div></pre></td></tr></table></figure>
<p>一个文件放到 Git 仓库只需要两步。</p>
<ol>
<li>用命令<code>git add</code>告诉 Git，把文件添加到仓库：</li>
</ol>
<figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ git <span class="keyword">add</span><span class="bash"> .  <span class="comment"># 把所有文件都添加到仓库</span></span></div></pre></td></tr></table></figure>
<p>执行上面的命令，没有任何显示，这就对了，Unix 的哲学是“没有消息就是好消息”，说明添加成功。（因为没有添加任何文件，如果添加结果不同，可以使用 <code>git status</code> 随时查看 <code>Git</code> 状态）</p>
<ol>
<li>用命令<code>git commit</code>告诉 Git，把文件提交到仓库：</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">$ git <span class="keyword">commit</span> abc/aaa.py -m<span class="string">"chore:wrote a readme file"</span></div><div class="line">[<span class="keyword">master</span> (root-<span class="keyword">commit</span>) cb926e7] wrote a readme <span class="keyword">file</span></div><div class="line"> <span class="number">1</span> <span class="keyword">file</span> <span class="keyword">changed</span>, <span class="number">2</span> insertions(+)</div><div class="line"> <span class="keyword">create</span> <span class="keyword">mode</span> <span class="number">100644</span> aaa.py</div></pre></td></tr></table></figure>
<p>commit 必须遵循commit规范<br><figure class="highlight haml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">**git commit规范**</div><div class="line"></div><div class="line">-<span class="ruby"> feat：新功能（feature）</span></div><div class="line">-<span class="ruby"> fix：修补bug</span></div><div class="line">-<span class="ruby"> docs：文档（documentation）</span></div><div class="line">-<span class="ruby"> style： 格式（不影响代码运行的变动）</span></div><div class="line">-<span class="ruby"> refactor：重构（即不是新增功能，也不是修改bug的代码变动）</span></div><div class="line">-<span class="ruby"> test：增加测试</span></div><div class="line">-<span class="ruby"> chore：构建过程或辅助工具的变动</span></div></pre></td></tr></table></figure></p>
<h2 id="2-新机器配置-Git"><a href="#2-新机器配置-Git" class="headerlink" title="2. 新机器配置 Git"></a>2. 新机器配置 Git</h2><ol>
<li>创建 SSH Key。在用户主目录下，看看有没有<code>.ssh</code>目录，如果有，再看看这个目录下有没有<code>id_rsa</code>和<code>id_rsa.pub</code>这两个文件，如果已经有了，可直接跳到第2步。如果没有，打开 Shell（Windows 下打开 Git Bash），创建 SSH Key：</li>
</ol>
<figure class="highlight elixir"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="variable">$ </span>ssh-keygen -t rsa -C <span class="string">"你的github邮箱"</span></div></pre></td></tr></table></figure>
<p>把邮件地址换成你自己的邮件地址，一路回车，使用默认值即可，无需设置密码。</p>
<p>如果一切顺利的话，可以在用户主目录里找到<code>.ssh</code>目录，里面有 id_rsa 和 id_rsa.pub 两个文件，这两个就是 SSH Key 的秘钥对，<code>id_rsa</code>是私钥，不能泄露出去，<code>id_rsa.pub</code>是公钥，可以放心地告诉任何人。</p>
<ol>
<li>登陆 GitHub，打开“Account settings”，“SSH Keys”页面：</li>
</ol>
<p>然后，点“Add SSH Key”，填上任意 Title，在 Key 文本框里粘贴<code>id_rsa.pub</code>文件的内容：</p>
<p><img src="http://wiki.jikexueyuan.com/project/git-tutorial/images/git13.png" alt="img"></p>
<p>点“Add Key”，你就应该看到已经添加的 Key</p>
<p><img src="http://wiki.jikexueyuan.com/project/git-tutorial/images/git16.png" alt="img"></p>
<p>当然，GitHub 允许你添加多个 Key。假定你有若干电脑，你一会儿在公司提交，一会儿在家里提交，只要把每台电脑的 Key 都添加到 GitHub，就可以在每台电脑上往 GitHub 推送了。</p>
<h2 id="3-关联远程库"><a href="#3-关联远程库" class="headerlink" title="3. 关联远程库"></a>3. 关联远程库</h2><ol>
<li><p>如果公司已创建该项目的远程库，本地还没有，clone 该项目地址: clone with ssh</p>
<p> <img src="/Users/offer/Desktop/clone.jpg" alt=""></p>
<figure class="highlight crmsh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ git <span class="keyword">clone</span> <span class="title">git</span>@github.com:xxxx/xxx.git</div></pre></td></tr></table></figure>
</li>
</ol>
<p><strong>SSH 警告</strong></p>
<p>   当你第一次使用 Git 的 clone 或者 push 命令连接 GitHub 时，会得到一个警告：</p>
   <figure class="highlight vbnet"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">The authenticity <span class="keyword">of</span> host <span class="comment">'github.com (xx.xx.xx.xx)' can't be established.</span></div><div class="line">RSA <span class="keyword">key</span> fingerprint <span class="keyword">is</span> xx.xx.xx.xx.xx.</div><div class="line">Are you sure you want <span class="keyword">to</span> <span class="keyword">continue</span> connecting (yes/no)?</div></pre></td></tr></table></figure>
<p>   这是因为 Git 使用 SSH 连接，而 SSH 连接在第一次验证 GitHub 服务器的 Key 时，需要你确认 GitHub 的 Key 的指纹信息是否真的来自 GitHub 的服务器，输入 yes 回车即可。</p>
<p>   Git 会输出一个警告，告诉你已经把 GitHub 的 Key 添加到本机的一个信任列表里了：</p>
   <figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Warning: Permanently added <span class="string">'github.com'</span> (RSA) <span class="built_in">to</span> <span class="keyword">the</span> list <span class="keyword">of</span> known hosts.</div></pre></td></tr></table></figure>
<p>   这个警告只会出现一次，后面的操作就不会有任何警告了。</p>
<p>   ​</p>
<ol>
<li><p>如果已经在本地创建了一个 Git 仓库后，公司也已在 GitHub 创建一个 Git 仓库，</p>
<ul>
<li>实现让这两个仓库进行远程同步</li>
</ul>
<figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ git remote <span class="keyword">add</span><span class="bash"> origin git@github.com:xxxx/xxxx.git</span></div></pre></td></tr></table></figure>
<ul>
<li><p>下一步，就可以把本地库的所有内容推送到远程库上</p>
<figure class="highlight maxima"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ git <span class="built_in">push</span> -u <span class="built_in">origin</span> master</div></pre></td></tr></table></figure>
<p>把本地库的内容推送到远程，用<code>git push</code>命令，实际上是把当前分支 master 推送到远程。</p>
<p>由于远程库是空的，我们第一次推送 master 分支时，加上了<code>-u</code>参数，Git 不但会把本地的 master 分支内容推送的远程新的 master 分支，还会把本地的 master 分支和远程的 master 分支关联起来，在以后的推送或者拉取时就可以简化命令。</p>
<p>推送成功后，可以立刻在 GitHub 页面中看到远程库的内容已经和本地一模一样</p>
<p>从现在起，只要本地作了提交，就可以通过命令：</p>
<p>$ git push origin master 把本地master分支的最新修改推送至GitHub</p>
</li>
</ul>
</li>
<li><p>一般我们在develop分支开发</p>
<ol>
<li>如果github上<strong>没有develop分支</strong></li>
</ol>
<ul>
<li><p>首先，我们在本地创建 develop 分支，然后切换到 develop 分支：</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ git checkout -<span class="selector-tag">b</span> develop</div><div class="line">Switched to <span class="selector-tag">a</span> new branch <span class="string">'develop'</span></div></pre></td></tr></table></figure>
<p><code>git checkout</code>命令加上<code>-b</code>参数表示创建并切换，相当于以下两条命令：</p>
<figure class="highlight armasm"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">$ git <span class="keyword">branch </span>develop</div><div class="line">$ git checkout develop</div><div class="line"><span class="keyword">Switched </span>to <span class="keyword">branch </span><span class="string">'develop'</span></div></pre></td></tr></table></figure>
<p>然后，用<code>git branch</code>命令查看当前分支：</p>
<figure class="highlight gams"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="symbol">$</span> git branch</div><div class="line"><span class="comment">* develop</span></div><div class="line">  master</div></pre></td></tr></table></figure>
<p><code>git branch</code>命令会列出所有分支，当前分支前面会标一个<code>*</code>号</p>
</li>
<li><p>发布develop分支</p>
<p>发布dev分支指的是同步develop分支的代码到远程服务器</p>
<figure class="highlight avrasm"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">git <span class="keyword">push</span> origin develop:develop    <span class="meta"># 这样远程仓库也有一个develop分支了 或者</span></div><div class="line">git <span class="keyword">push</span> origin develop  <span class="meta"># 这两种应该都可以</span></div></pre></td></tr></table></figure>
</li>
</ul>
<ol>
<li><p>如果github已经<strong>有master分支和develop分支</strong></p>
<p>在本地</p>
<p><code>git checkout -b develop</code> 新建并切换到本地develop分支</p>
<p><code>git pull origin develop</code>  本地develop分支与远程develop分支相关联</p>
</li>
</ol>
</li>
</ol>
<hr>
<h1 id="Git-总结"><a href="#Git-总结" class="headerlink" title="Git 总结"></a>Git 总结</h1><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">git <span class="keyword">add </span>.  <span class="comment"># 添加所有改动的文件到仓库</span></div><div class="line">git commit 文件路径 -m<span class="string">'fix:修复xx bug'</span></div><div class="line"></div><div class="line"><span class="comment"># github上已经有master分支 和dev分支在本地</span></div><div class="line">git checkout -<span class="keyword">b </span>dev <span class="comment"># 创建+切换分支dev</span></div><div class="line">git pull <span class="keyword">origin </span>dev <span class="comment"># 本地分支与远程分支相关联dev</span></div><div class="line"></div><div class="line"><span class="comment"># github无dev分支，在本地新建分支并推送到远程</span></div><div class="line">git checkout -<span class="keyword">b </span>dev</div><div class="line">git push <span class="keyword">origin </span>dev:dev  <span class="comment"># 这样远程仓库中也就创建了一个dev分支</span></div><div class="line"></div><div class="line">git <span class="keyword">branch </span> <span class="comment"># 查看本地有多少分支</span></div><div class="line">git <span class="keyword">branch </span>分支名字 <span class="comment"># 创建分支</span></div><div class="line">git checkout dev <span class="comment"># 切换到dev分支进行开发</span></div><div class="line">git push <span class="comment"># 提交到远程</span></div><div class="line">git <span class="keyword">branch </span>-d dev <span class="comment"># 删除本地dev分支</span></div><div class="line">git merge dev <span class="comment"># 合并dev到当前分支(master)</span></div></pre></td></tr></table></figure>
<h1 id="git-remote-深入研究"><a href="#git-remote-深入研究" class="headerlink" title="git remote 深入研究"></a>git remote 深入研究</h1><blockquote>
<p>git-remote - Manage set of tracked repositories</p>
</blockquote>
<figure class="highlight dsconfig"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="string">git </span><span class="string">remote </span>[-v | <span class="built_in">--verbose]</span></div><div class="line"><span class="string">git </span><span class="string">remote </span><span class="string">add </span>[-t &lt;<span class="string">branch&gt;</span>] [-m &lt;<span class="string">master&gt;</span>] [-f] [--[<span class="string">no-</span>]<span class="string">tags]</span> [<span class="built_in">--mirror=&lt;fetch|push&gt;]</span> &lt;<span class="string">name&gt;</span> &lt;<span class="string">url&gt;</span></div><div class="line"><span class="string">git </span><span class="string">remote </span><span class="string">rename </span>&lt;<span class="string">old&gt;</span> &lt;<span class="string">new&gt;</span></div><div class="line"><span class="string">git </span><span class="string">remote </span><span class="string">remove </span>&lt;<span class="string">name&gt;</span></div><div class="line"><span class="string">git </span><span class="string">remote </span><span class="built_in">set-head</span> &lt;<span class="string">name&gt;</span> (-a | <span class="built_in">--auto</span> | -d | <span class="built_in">--delete</span> | &lt;<span class="string">branch&gt;</span>)</div><div class="line"><span class="string">git </span><span class="string">remote </span><span class="built_in">set-branches</span> [<span class="built_in">--add]</span> &lt;<span class="string">name&gt;</span> &lt;<span class="string">branch&gt;</span>…​</div><div class="line"><span class="string">git </span><span class="string">remote </span><span class="built_in">get-url</span> [<span class="built_in">--push]</span> [<span class="built_in">--all]</span> &lt;<span class="string">name&gt;</span></div><div class="line"><span class="string">git </span><span class="string">remote </span><span class="built_in">set-url</span> [<span class="built_in">--push]</span> &lt;<span class="string">name&gt;</span> &lt;<span class="string">newurl&gt;</span> [&lt;<span class="string">oldurl&gt;</span>]</div><div class="line"><span class="string">git </span><span class="string">remote </span><span class="built_in">set-url</span> <span class="built_in">--add</span> [<span class="built_in">--push]</span> &lt;<span class="string">name&gt;</span> &lt;<span class="string">newurl&gt;</span></div><div class="line"><span class="string">git </span><span class="string">remote </span><span class="built_in">set-url</span> <span class="built_in">--delete</span> [<span class="built_in">--push]</span> &lt;<span class="string">name&gt;</span> &lt;<span class="string">url&gt;</span></div><div class="line"><span class="string">git </span><span class="string">remote </span>[-v | <span class="built_in">--verbose]</span> <span class="string">show </span>[-n] &lt;<span class="string">name&gt;</span>…​</div><div class="line"><span class="string">git </span><span class="string">remote </span><span class="string">prune </span>[-n | <span class="built_in">--dry-run]</span> &lt;<span class="string">name&gt;</span>…​</div><div class="line"><span class="string">git </span><span class="string">remote </span>[-v | <span class="built_in">--verbose]</span> <span class="string">update </span>[-p | <span class="built_in">--prune]</span> [(&lt;<span class="string">group&gt;</span> | &lt;<span class="string">remote&gt;</span>)…​]</div></pre></td></tr></table></figure>
<h2 id="查看远程仓库"><a href="#查看远程仓库" class="headerlink" title="查看远程仓库"></a>查看远程仓库</h2><p>如果想查看你已经配置的远程仓库服务器，可以运行 <code>git remote</code> 命令。 它会列出你指定的每一个远程服务器的简写。 如果你已经克隆了自己的仓库，那么至少应该能看到 <code>origin -</code> 这是 <code>Git</code> 给你克隆的仓库服务器的默认名字：</p>
<figure class="highlight gams"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="symbol">$</span> git clone https:<span class="comment">//github.com/schacon/ticgit</span></div><div class="line"><span class="function"><span class="title">Cloning</span></span> into <span class="string">'ticgit'</span>...</div><div class="line">remote: Reusing existing pack: <span class="number">1857</span>, done.</div><div class="line">remote: Total <span class="number">1857</span> (delta <span class="number">0</span>), reused <span class="number">0</span> (delta <span class="number">0</span>)</div><div class="line">Receiving objects: <span class="number">100</span>% (<span class="number">1857</span>/<span class="number">1857</span>), <span class="number">374.35</span> KiB | <span class="number">268.00</span> KiB/s, done.</div><div class="line">Resolving deltas: <span class="number">100</span>% (<span class="number">772</span>/<span class="number">772</span>), done.</div><div class="line"><span class="function"><span class="title">Checking</span></span> connectivity... done.</div><div class="line"><span class="symbol">$</span> cd ticgit</div><div class="line"><span class="symbol">$</span> git remote</div><div class="line">origin</div></pre></td></tr></table></figure>
<p>你也可以指定选项 <code>-v</code>，会显示需要读写远程仓库使用的 <code>Git</code> 保存的简写与其对应的 URL。<br><figure class="highlight awk"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">$ git remote -v</div><div class="line">origin	https:<span class="regexp">//gi</span>thub.com<span class="regexp">/schacon/</span>ticgit (fetch)</div><div class="line">origin	https:<span class="regexp">//gi</span>thub.com<span class="regexp">/schacon/</span>ticgit (push)</div></pre></td></tr></table></figure></p>
<p>如果你的远程仓库不止一个，该命令会将它们全部列出。 例如，与几个协作者合作的，拥有多个远程仓库的仓库看起来像下面这样：</p>
<figure class="highlight groovy"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">$ cd grit</div><div class="line">$ git remote -v</div><div class="line">bakkdoor  <span class="string">https:</span><span class="comment">//github.com/bakkdoor/grit (fetch)</span></div><div class="line">bakkdoor  <span class="string">https:</span><span class="comment">//github.com/bakkdoor/grit (push)</span></div><div class="line">cho45     <span class="string">https:</span><span class="comment">//github.com/cho45/grit (fetch)</span></div><div class="line">cho45     <span class="string">https:</span><span class="comment">//github.com/cho45/grit (push)</span></div><div class="line">defunkt   <span class="string">https:</span><span class="comment">//github.com/defunkt/grit (fetch)</span></div><div class="line">defunkt   <span class="string">https:</span><span class="comment">//github.com/defunkt/grit (push)</span></div><div class="line">koke      <span class="string">git:</span><span class="comment">//github.com/koke/grit.git (fetch)</span></div><div class="line">koke      <span class="string">git:</span><span class="comment">//github.com/koke/grit.git (push)</span></div><div class="line">origin    git<span class="meta">@github</span>.<span class="string">com:</span>mojombo/grit.git (fetch)</div><div class="line">origin    git<span class="meta">@github</span>.<span class="string">com:</span>mojombo/grit.git (push)</div></pre></td></tr></table></figure>
<p>这样我们可以轻松拉取其中任何一个用户的贡献。 此外，我们大概还会有某些远程仓库的推送权限，虽然我们目前还不会在此介绍。</p>
<p>注意这些远程仓库使用了不同的协议；我们将会在 <a href="https://git-scm.com/book/zh/v2/%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A%E7%9A%84-Git-%E5%9C%A8%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A%E6%90%AD%E5%BB%BA-Git#r_git_on_the_server" target="_blank" rel="external">在服务器上搭建 Git</a> 中了解关于它们的更多信息。</p>
<h2 id="添加远程仓库"><a href="#添加远程仓库" class="headerlink" title="添加远程仓库"></a>添加远程仓库</h2><p>运行 <code>git remote add &lt;shortname&gt; &lt;url&gt;</code> 添加一个新的远程 <code>Git</code> 仓库，同时指定一个你可以轻松引用的简写：<br><figure class="highlight vim"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">$ git remote</div><div class="line">origin</div><div class="line">$ git remote <span class="built_in">add</span> pb http<span class="variable">s:</span>//github.<span class="keyword">com</span>/paulboone/ticgit</div><div class="line">$ git remote -v</div><div class="line">origin	http<span class="variable">s:</span>//github.<span class="keyword">com</span>/schacon/ticgit (fetch)</div><div class="line">origin	http<span class="variable">s:</span>//github.<span class="keyword">com</span>/schacon/ticgit (push)</div><div class="line">pb	http<span class="variable">s:</span>//github.<span class="keyword">com</span>/paulboone/ticgit (fetch)</div><div class="line">pb	http<span class="variable">s:</span>//github.<span class="keyword">com</span>/paulboone/ticgit (push)</div></pre></td></tr></table></figure></p>
<p>现在你可以在命令行中使用字符串 <code>pb</code> 来代替整个 <code>URL</code>。 例如，如果你想拉取 <code>Paul</code> 的仓库中有但你没有的信息，可以运行 <code>git fetch pb</code>：<br><figure class="highlight groovy"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">$ git fetch pb</div><div class="line"><span class="string">remote:</span> Counting <span class="string">objects:</span> <span class="number">43</span>, done.</div><div class="line"><span class="string">remote:</span> Compressing <span class="string">objects:</span> <span class="number">100</span>% (<span class="number">36</span>/<span class="number">36</span>), done.</div><div class="line"><span class="string">remote:</span> Total <span class="number">43</span> (delta <span class="number">10</span>), reused <span class="number">31</span> (delta <span class="number">5</span>)</div><div class="line">Unpacking <span class="string">objects:</span> <span class="number">100</span>% (<span class="number">43</span>/<span class="number">43</span>), done.</div><div class="line">From <span class="string">https:</span><span class="comment">//github.com/paulboone/ticgit</span></div><div class="line"> * [<span class="keyword">new</span> branch]      master     -&gt; pb/master</div><div class="line"> * [<span class="keyword">new</span> branch]      ticgit     -&gt; pb/ticgit</div></pre></td></tr></table></figure></p>
<p>现在 <code>Paul</code> 的 <code>master</code> 分支可以在本地通过 <code>pb/master</code> 访问到 - 你可以将它合并到自己的某个分支中，或者如果你想要查看它的话，可以检出一个指向该点的本地分支。 </p>
<p>##从远程仓库中抓取与拉取<br>就如刚才所见，从远程仓库中获得数据，可以执行：</p>
<p><code>$ git fetch [remote-name]</code><br>这个命令会访问远程仓库，从中拉取所有你还没有的数据。 执行完成后，你将会拥有那个远程仓库中所有分支的引用，可以随时合并或查看。</p>
<p>如果你使用 <code>clone</code> 命令克隆了一个仓库，命令会自动将其添加为远程仓库并默认以 “origin” 为简写。 所以，<code>git fetch origin</code> 会抓取克隆（或上一次抓取）后新推送的所有工作。 必须注意 <code>git fetch</code> 命令会将数据拉取到你的本地仓库 - 它并不会自动合并或修改你当前的工作。 当准备好时你必须手动将其合并入你的工作。</p>
<p>如果你有一个分支设置为跟踪一个远程分支，可以使用 <code>git pull</code> 命令来自动的抓取然后合并远程分支到当前分支。 这对你来说可能是一个更简单或更舒服的工作流程；默认情况下，<code>git clone</code> 命令会自动设置本地 <code>master</code> 分支跟踪克隆的远程仓库的 <code>master</code> 分支（或不管是什么名字的默认分支）。 运行 <code>git pull</code> 通常会从最初克隆的服务器上抓取数据并自动尝试合并到当前所在的分支。</p>
<h2 id="推送到远程仓库"><a href="#推送到远程仓库" class="headerlink" title="推送到远程仓库"></a>推送到远程仓库</h2><p>当你想分享你的项目时，必须将其推送到上游。 这个命令很简单：<code>git push [remote-name] [branch-name]</code>。 当你想要将 <code>master</code> 分支推送到 <code>origin</code> 服务器时（再次说明，克隆时通常会自动帮你设置好那两个名字），那么运行这个命令就可以将你所做的备份到服务器：</p>
<p><code>$ git push origin master</code><br>只有当你有所克隆服务器的写入权限，并且之前没有人推送过时，这条命令才能生效。 当你和其他人在同一时间克隆，他们先推送到上游然后你再推送到上游，你的推送就会毫无疑问地被拒绝。 你必须先将他们的工作拉取下来并将其合并进你的工作后才能推送。</p>
<h2 id="查看远程仓库-1"><a href="#查看远程仓库-1" class="headerlink" title="查看远程仓库"></a>查看远程仓库</h2><p>如果想要查看某一个远程仓库的更多信息，可以使用 <code>git remote show [remote-name]</code> 命令。 如果想以一个特定的缩写名运行这个命令，例如 <code>origin</code>，会得到像下面类似的信息：<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">$ git remote <span class="keyword">show</span> origin</div><div class="line">* remote origin</div><div class="line">  <span class="keyword">Fetch</span> <span class="keyword">URL</span>: https://github.com/schacon/ticgit</div><div class="line">  Push  <span class="keyword">URL</span>: https://github.com/schacon/ticgit</div><div class="line">  <span class="keyword">HEAD</span> branch: <span class="keyword">master</span></div><div class="line">  Remote branches:</div><div class="line">    <span class="keyword">master</span>                               tracked</div><div class="line">    dev-branch                           tracked</div><div class="line">  <span class="keyword">Local</span> branch configured <span class="keyword">for</span> <span class="string">'git pull'</span>:</div><div class="line">    <span class="keyword">master</span> merges <span class="keyword">with</span> remote <span class="keyword">master</span></div><div class="line">  <span class="keyword">Local</span> <span class="keyword">ref</span> configured <span class="keyword">for</span> <span class="string">'git push'</span>:</div><div class="line">    <span class="keyword">master</span> pushes <span class="keyword">to</span> <span class="keyword">master</span> (up <span class="keyword">to</span> <span class="built_in">date</span>)</div></pre></td></tr></table></figure></p>
<p>它同样会列出远程仓库的 <code>URL</code> 与跟踪分支的信息。 这些信息非常有用，它告诉你正处于 <code>master</code> 分支，并且如果运行 <code>git pull</code>，就会抓取所有的远程引用，然后将远程 <code>master</code> 分支合并到本地 <code>master</code> 分支。 它也会列出拉取到的所有远程引用。</p>
<p>这是一个经常遇到的简单例子。 如果你是 <code>Git</code> 的重度使用者，那么还可以通过 <code>git remote show</code> 看到更多的信息。<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line">$ git remote <span class="keyword">show</span> origin</div><div class="line">* remote origin</div><div class="line">  <span class="keyword">URL</span>: https://github.com/my-org/complex-<span class="keyword">project</span></div><div class="line">  <span class="keyword">Fetch</span> <span class="keyword">URL</span>: https://github.com/my-org/complex-<span class="keyword">project</span></div><div class="line">  Push  <span class="keyword">URL</span>: https://github.com/my-org/complex-<span class="keyword">project</span></div><div class="line">  <span class="keyword">HEAD</span> branch: <span class="keyword">master</span></div><div class="line">  Remote branches:</div><div class="line">    <span class="keyword">master</span>                           tracked</div><div class="line">    dev-branch                       tracked</div><div class="line">    markdown-strip                   tracked</div><div class="line">    issue<span class="number">-43</span>                         <span class="keyword">new</span> (<span class="keyword">next</span> <span class="keyword">fetch</span> will <span class="keyword">store</span> <span class="keyword">in</span> remotes/origin)</div><div class="line">    issue<span class="number">-45</span>                         <span class="keyword">new</span> (<span class="keyword">next</span> <span class="keyword">fetch</span> will <span class="keyword">store</span> <span class="keyword">in</span> remotes/origin)</div><div class="line">    refs/remotes/origin/issue<span class="number">-11</span>     stale (<span class="keyword">use</span> <span class="string">'git remote prune'</span> <span class="keyword">to</span> remove)</div><div class="line">  <span class="keyword">Local</span> branches configured <span class="keyword">for</span> <span class="string">'git pull'</span>:</div><div class="line">    dev-branch merges <span class="keyword">with</span> remote dev-branch</div><div class="line">    <span class="keyword">master</span>     merges <span class="keyword">with</span> remote <span class="keyword">master</span></div><div class="line">  <span class="keyword">Local</span> refs configured <span class="keyword">for</span> <span class="string">'git push'</span>:</div><div class="line">    dev-branch                     pushes <span class="keyword">to</span> dev-branch                     (up <span class="keyword">to</span> <span class="built_in">date</span>)</div><div class="line">    markdown-strip                 pushes <span class="keyword">to</span> markdown-strip                 (up <span class="keyword">to</span> <span class="built_in">date</span>)</div><div class="line">    <span class="keyword">master</span>                         pushes <span class="keyword">to</span> <span class="keyword">master</span>                         (up <span class="keyword">to</span> <span class="built_in">date</span>)</div></pre></td></tr></table></figure></p>
<p>这个命令列出了当你在特定的分支上执行 <code>git push</code> 会自动地推送到哪一个远程分支。 它也同样地列出了哪些远程分支不在你的本地，哪些远程分支已经从服务器上移除了，还有当你执行 <code>git pull</code> 时哪些分支会自动合并。</p>
<h2 id="远程仓库的移除与重命名"><a href="#远程仓库的移除与重命名" class="headerlink" title="远程仓库的移除与重命名"></a>远程仓库的移除与重命名</h2><p>如果想要重命名引用的名字可以运行 <code>git remote rename</code> 去修改一个远程仓库的简写名。 例如，想要将 <code>pb</code> 重命名为 <code>paul</code>，可以用 <code>git remote rename</code> 这样做：<br><figure class="highlight elixir"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="variable">$ </span>git remote rename pb paul</div><div class="line"><span class="variable">$ </span>git remote</div><div class="line">origin</div><div class="line">paul</div></pre></td></tr></table></figure></p>
<p>值得注意的是这同样也会修改你的远程分支名字。 那些过去引用 <code>pb/master</code> 的现在会引用 <code>paul/master</code>。</p>
<p>如果因为一些原因想要移除一个远程仓库 - 你已经从服务器上搬走了或不再想使用某一个特定的镜像了，又或者某一个贡献者不再贡献了 - 可以使用 <code>git remote rm</code> ：<br><figure class="highlight elixir"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="variable">$ </span>git remote rm paul</div><div class="line"><span class="variable">$ </span>git remote</div><div class="line">origin</div></pre></td></tr></table></figure></p>
<h1 id="回顾：学习Git（一）起步"><a href="#回顾：学习Git（一）起步" class="headerlink" title="回顾：学习Git（一）起步"></a>回顾：<a href="https://zhangslob.github.io/2018/03/14/%E5%AD%A6%E4%B9%A0Git%EF%BC%88%E4%B8%80%EF%BC%89%E8%B5%B7%E6%AD%A5/">学习Git（一）起步</a></h1>]]></content>
    
    <summary type="html">
    
      &lt;pre&gt;&lt;code&gt;这是崔斯特的第三十七篇原创文章
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;继续补基础  (๑• . •๑)&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/nSjj0lk.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Git" scheme="https://zhangslob.github.io/categories/Git/"/>
    
    
      <category term="Git" scheme="https://zhangslob.github.io/tags/Git/"/>
    
  </entry>
  
  <entry>
    <title>学习Git（一）起步</title>
    <link href="https://zhangslob.github.io/2018/03/14/%E5%AD%A6%E4%B9%A0Git%EF%BC%88%E4%B8%80%EF%BC%89%E8%B5%B7%E6%AD%A5/"/>
    <id>https://zhangslob.github.io/2018/03/14/学习Git（一）起步/</id>
    <published>2018-03-14T14:52:36.000Z</published>
    <updated>2018-03-19T15:12:28.919Z</updated>
    
    <content type="html"><![CDATA[<pre><code>这是崔斯特的第三十六篇原创文章
</code></pre><p>开始补基础  (๑• . •๑)</p>
<p><img src="https://i.imgur.com/nSjj0lk.png" alt=""></p>
<a id="more"></a>
<h1 id="什么是Git"><a href="#什么是Git" class="headerlink" title="什么是Git"></a>什么是Git</h1><p>在Git官网上找到这样一段描述</p>
<blockquote>
<p>Git is a free and open source distributed version control system designed to handle everything from small to very large projects with speed and efficiency.</p>
</blockquote>
<p>重点是 <code>version control system</code> (VCS)，翻译过来也就是 <code>版本控制系统</code>。（Pycharm中有一个）</p>
<h2 id="关于版本控制"><a href="#关于版本控制" class="headerlink" title="关于版本控制"></a>关于版本控制</h2><p>版本控制是一种记录一个或若干文件内容变化，以便将来查阅特定版本修订情况的系统。</p>
<p>（我的理解就是一个东西会有不同的版本，就像吃鸡，常常更新，每更新一次就是一个新的版本，如果刚发行的版本出现毒圈不掉血，这个时候就需要版本回退。。版本控制系统就体现作用了）</p>
<p>版本控制系统又分为：本地版本控制系统、集中化的版本控制系统、分布式版本控制系统。</p>
<p><img src="https://git-scm.com/book/en/v2/images/local.png" alt=""></p>
<blockquote>
<p>本地版本控制系统</p>
</blockquote>
<p><img src="https://git-scm.com/book/en/v2/images/centralized.png" alt=""></p>
<blockquote>
<p>集中化的版本控制系统</p>
</blockquote>
<p><img src="https://git-scm.com/book/en/v2/images/distributed.png" alt=""></p>
<blockquote>
<p>分布式版本控制系统</p>
</blockquote>
<p>更多介绍可以来看 <a href="https://git-scm.com/book/zh/v2/%E8%B5%B7%E6%AD%A5-%E5%85%B3%E4%BA%8E%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6" target="_blank" rel="external">1.1 起步 - 关于版本控制</a></p>
<h1 id="谁开发了-Git"><a href="#谁开发了-Git" class="headerlink" title="谁开发了 Git"></a>谁开发了 Git</h1><p>2002 年，Linux 内核开源项目组开始启用一个专有的分布式版本控制系统 <code>BitKeeper</code> 来管理和维护代码。</p>
<p>但是到了 2005 年，开发 <code>BitKeeper</code> 的商业公司同 <code>Linux</code> 内核开源社区的合作关系结束，他们收回了 <code>Linux</code> 内核社区免费使用 <code>BitKeeper</code> 的权力。 这就迫使 <code>Linux</code> 开源社区（特别是 <code>Linux</code> 的缔造者 <code>Linus Torvalds</code>）基于使用 <code>BitKeeper</code> 时的经验教训，开发出自己的版本系统。 他们对新的系统制订了若干目标：</p>
<ul>
<li>速度</li>
<li>简单的设计</li>
<li>对非线性开发模式的强力支持（允许成千上万个并行开发的分支）</li>
<li>完全分布式</li>
<li>有能力高效管理类似 Linux 内核一样的超大规模项目（速度和数据量）</li>
</ul>
<h1 id="Git-特点"><a href="#Git-特点" class="headerlink" title="Git 特点"></a>Git 特点</h1><h2 id="Git-工作流"><a href="#Git-工作流" class="headerlink" title="Git 工作流"></a>Git 工作流</h2><p>基本的 Git 工作流程如下：</p>
<ol>
<li>克隆 Git 资源作为工作目录。</li>
<li>在克隆的资源上添加或修改文件。</li>
<li>如果其他人修改了，你可以更新资源。</li>
<li>在提交前查看修改。</li>
<li>提交修改。</li>
<li>在修改完成后，如果发现错误，可以撤回提交并再次修改并提交。</li>
</ol>
<h2 id="近乎所有操作都是本地执行"><a href="#近乎所有操作都是本地执行" class="headerlink" title="近乎所有操作都是本地执行"></a>近乎所有操作都是本地执行</h2><p>在 <code>Git</code> 中的绝大多数操作都只需要访问本地文件和资源，一般不需要来自网络上其它计算机的信息。</p>
<p>举个例子，要浏览项目的历史，<code>Git</code> 不需外连到服务器去获取历史，然后再显示出来——它只需直接从本地数据库中读取。 你能立即看到项目历史。 如果你想查看当前版本与一个月前的版本之间引入的修改，<code>Git</code> 会查找到一个月前的文件做一次本地的差异计算，而不是由远程服务器处理或从远程服务器拉回旧版本文件再来本地处理。</p>
<h2 id="Git-保证完整性"><a href="#Git-保证完整性" class="headerlink" title="Git 保证完整性"></a>Git 保证完整性</h2><p><code>Git</code> 中所有数据在存储前都计算校验和，然后以校验和来引用。 这意味着不可能在 <code>Git</code> 不知情时更改任何文件内容或目录内容。 这个功能建构在 <code>Git</code> 底层，是构成 <code>Git</code> 哲学不可或缺的部分。 若你在传送过程中丢失信息或损坏文件，<code>Git</code> 就能发现。</p>
<p><code>Git</code> 用以计算校验和的机制叫做 <code>SHA-1</code> 散列（hash，哈希）。 这是一个由 40 个十六进制字符（0-9 和 a-f）组成字符串，基于 <code>Git</code> 中文件的内容或目录结构计算出来。 <code>SHA-1</code> 哈希看起来是这样：</p>
<p><code>24b9da6552252987aa493b52f8696cd6d3b00373</code></p>
<p><code>Git</code> 中使用这种哈希值的情况很多，你将经常看到这种哈希值。 实际上，<code>Git</code> 数据库中保存的信息都是以文件内容的哈希值来索引，而不是文件名。</p>
<h2 id="Git-一般只添加数据"><a href="#Git-一般只添加数据" class="headerlink" title="Git 一般只添加数据"></a>Git 一般只添加数据</h2><p>你执行的 <code>Git</code> 操作，几乎只往 <code>Git</code> 数据库中增加数据。 很难让 <code>Git</code> 执行任何不可逆操作，或者让它以任何方式清除数据。 同别的 <code>VCS</code> 一样，未提交更新时有可能丢失或弄乱修改的内容；但是一旦你提交快照到 <code>Git</code> 中，就难以再丢失数据，特别是如果你定期的推送数据库到其它仓库的话。</p>
<h2 id="Git-的三种状态"><a href="#Git-的三种状态" class="headerlink" title="Git 的三种状态"></a>Git 的三种状态</h2><ol>
<li>已提交（committed）：数据已经安全的保存在本地数据库中。</li>
<li>已修改（modified） ：修改了文件，但还没保存到数据库中。</li>
<li>已暂存（staged）   ：对一个已修改文件的当前版本做了标记，使之包含在下次提交的快照中。</li>
</ol>
<p>由此引入 Git 项目的三个工作区域的概念：Git 仓库、工作目录以及暂存区域。</p>
<p><img src="https://git-scm.com/book/en/v2/images/areas.png" alt=""></p>
<h1 id="安装-Git"><a href="#安装-Git" class="headerlink" title="安装 Git"></a>安装 Git</h1><p>说了那么多，现在开始动手，安装Git。</p>
<h2 id="Linux"><a href="#Linux" class="headerlink" title="Linux"></a>Linux</h2><p><code>$ sudo yum install git</code></p>
<p>或者</p>
<p><code>$ sudo apt-get install git</code></p>
<h2 id="Mac"><a href="#Mac" class="headerlink" title="Mac"></a>Mac</h2><p>下载安装包 <a href="https://git-scm.com/download/mac" target="_blank" rel="external">Downloading Git</a></p>
<p>或者</p>
<p><code>$ brew install git</code></p>
<h2 id="Windows"><a href="#Windows" class="headerlink" title="Windows"></a>Windows</h2><p>直接下载文件 <a href="https://git-scm.com/download/win" target="_blank" rel="external">Downloading Git</a></p>
<p>或者</p>
<p>安装 <a href="https://desktop.github.com/" target="_blank" rel="external">GitHub for Windows</a></p>
<h1 id="初次运行-Git-前的配置"><a href="#初次运行-Git-前的配置" class="headerlink" title="初次运行 Git 前的配置"></a>初次运行 Git 前的配置</h1><h2 id="用户信息"><a href="#用户信息" class="headerlink" title="用户信息"></a>用户信息</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ git config --global user.name &quot;name&quot;</div><div class="line">$ git config --global user.email example@example.com</div></pre></td></tr></table></figure>
<p>如果使用了 <code>--global</code> 选项，那么该命令只需要运行一次，因为之后无论你在该系统上做任何事情， <code>Git</code> 都会使用那些信息。</p>
<h2 id="检查配置信息"><a href="#检查配置信息" class="headerlink" title="检查配置信息"></a>检查配置信息</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">$ git config --list</div><div class="line">user.name=name</div><div class="line">user.email=example@example.com</div><div class="line">color.status=auto</div><div class="line">color.branch=auto</div><div class="line">color.interactive=auto</div><div class="line">color.diff=auto</div><div class="line">...</div></pre></td></tr></table></figure>
<h2 id="获取帮助"><a href="#获取帮助" class="headerlink" title="获取帮助"></a>获取帮助</h2><p>若你使用 <code>Git</code> 时需要获取帮助，有三种方法可以找到 <code>Git</code> 命令的使用手册：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">$ git help &lt;verb&gt;</div><div class="line">$ git &lt;verb&gt; --help</div><div class="line">$ man git-&lt;verb&gt;</div></pre></td></tr></table></figure></p>
<p>例如，要想获得 <code>config</code> 命令的手册，执行</p>
<p><code>$ git help config</code></p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>以前只是了解 <code>Git</code>常见的push、commit等命令，从没有对 <code>Git</code>进性过系统学习，抓紧时间学习。</p>
<p><strong>目标</strong>：两周后，也就是3月28日，能熟练使用 <code>Git</code>进性开发。</p>
<p>这一篇主要讲了些背景知识吧，下一篇就是实际的操作了。</p>
<p>主要从<a href="https://git-scm.com/book/zh/v2" target="_blank" rel="external">Git文档</a>上截取自己认为重要的部分，有条件可以去仔细阅读。</p>
]]></content>
    
    <summary type="html">
    
      &lt;pre&gt;&lt;code&gt;这是崔斯特的第三十六篇原创文章
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;开始补基础  (๑• . •๑)&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/nSjj0lk.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Git" scheme="https://zhangslob.github.io/categories/Git/"/>
    
    
      <category term="Git" scheme="https://zhangslob.github.io/tags/Git/"/>
    
  </entry>
  
  <entry>
    <title>大佬，我代码哪错了？</title>
    <link href="https://zhangslob.github.io/2018/03/13/%E5%A4%A7%E4%BD%AC%EF%BC%8C%E6%88%91%E4%BB%A3%E7%A0%81%E5%93%AA%E9%94%99%E4%BA%86%EF%BC%9F/"/>
    <id>https://zhangslob.github.io/2018/03/13/大佬，我代码哪错了？/</id>
    <published>2018-03-13T13:30:03.000Z</published>
    <updated>2018-03-13T14:45:50.478Z</updated>
    
    <content type="html"><![CDATA[<pre><code>这是崔斯特的第三十五篇原创文章
</code></pre><p>到底哪错了  (๑• . •๑)</p>
<p><img src="https://i.imgur.com/pTw3VCX.jpg" alt=""></p>
<a id="more"></a>
<h1 id="问题无处不在"><a href="#问题无处不在" class="headerlink" title="问题无处不在"></a>问题无处不在</h1><p>我： “大佬，帮我看看这个问题错在哪了？”</p>
<p>大佬： “你的代码呢、你的错误提示呢？”</p>
<p>我： “好的，我发给你”</p>
<p><img src="https://i.imgur.com/4nSLl1h.jpg" alt=""></p>
<p>大佬： “。。。 再见”</p>
<p>留下一脸懵逼的我</p>
<p><img src="https://i.imgur.com/pe57y3U.jpg" alt=""></p>
<h1 id="如何解决问题"><a href="#如何解决问题" class="headerlink" title="如何解决问题"></a>如何解决问题</h1><p>最简单的方法是根据错误提示，查看对应位置的代码，Pycharm会提示具体是哪一行代码有问题，并抛出错误。</p>
<p>找到错误首先应自己想办法解决，自己解决又分为几种：有经验的大佬看到<code>Error</code>就知道是哪里有问题了，没经验怎么办，那就自己去搜索了。</p>
<p>下个结论，<strong>你遇到的问题，前人一定遇到过。</strong></p>
<p>所以你只需要把你的错误提示搜索就好了。</p>
<p>注意下面，你懂的。（给自己一个好点的环境）</p>
<blockquote>
<p>Google &gt; 百度</p>
<p>stackoverflow &gt; 知乎</p>
<p>github &gt; CSDN</p>
</blockquote>
<p>Github上有一个很有用的 <a href="https://github.com/trending" target="_blank" rel="external">trending</a> ，可以显示今天或本周或本月最火的项目，例如：</p>
<p><a href="https://github.com/techGay/91porn" target="_blank" rel="external">techGay/91porn</a></p>
<p><img src="https://i.imgur.com/v6RqtqZ.png" alt=""></p>
<p>Github 作为全球最大的同性交友网站，上面有很多值得我们好好学习的东西。</p>
<h1 id="如何向别人提问"><a href="#如何向别人提问" class="headerlink" title="如何向别人提问"></a>如何向别人提问</h1><p>如果你真的像上面哪样，发一张照片，估计大佬都要吐血了。</p>
<p>在这里推荐大家使用Github上的 <a href="https://gist.github.com/" target="_blank" rel="external">gist</a> ，很适合分享代码片段。</p>
<blockquote>
<p>Instantly share code, notes, and snippets.</p>
</blockquote>
<p>例如这样</p>
<p><a href="https://gist.github.com/zhangslob/b10a7753fb1b404c1111e09431da1433" target="_blank" rel="external">Issue in FromRequest #3144</a></p>
<p><img src="https://i.imgur.com/kkLvFTn.png" alt=""></p>
<p>这样看起来是不是舒服多了</p>
<h1 id="如何才能-永无bug"><a href="#如何才能-永无bug" class="headerlink" title="如何才能 永无bug"></a>如何才能 永无bug</h1><h2 id="1、佛祖保佑-永无bug"><a href="#1、佛祖保佑-永无bug" class="headerlink" title="1、佛祖保佑 永无bug"></a>1、佛祖保佑 永无bug</h2><figure class="highlight 1c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"><span class="comment">//                            _ooOoo_</span></div><div class="line"><span class="comment">//                           o8888888o</span></div><div class="line"><span class="comment">//                           88" . "88</span></div><div class="line"><span class="comment">//                           (| -_- |)</span></div><div class="line"><span class="comment">//                            O\ = /O</span></div><div class="line"><span class="comment">//                        ____/`---'\____</span></div><div class="line"><span class="comment">//                      .   ' \\| |// `.</span></div><div class="line"><span class="comment">//                       / \\||| : |||// \</span></div><div class="line"><span class="comment">//                     / _||||| -:- |||||- \</span></div><div class="line"><span class="comment">//                       | | \\\ - /// | |</span></div><div class="line"><span class="comment">//                     | \_| ''\---/'' | |</span></div><div class="line"><span class="comment">//                      \ .-\__ `-` ___/-. /</span></div><div class="line"><span class="comment">//                   ___`. .' /--.--\ `. . __</span></div><div class="line"><span class="comment">//                ."" '&lt; `.___\_&lt;|&gt;_/___.' &gt;'"".</span></div><div class="line"><span class="comment">//               | | : `- \`.;`\ _ /`;.`/ - ` : | |</span></div><div class="line"><span class="comment">//                 \ \ `-. \_ __\ /__ _/ .-` / /</span></div><div class="line"><span class="comment">//         ======`-.____`-.___\_____/___.-`____.-'======</span></div><div class="line"><span class="comment">//                            `=---='</span></div><div class="line"><span class="comment">//</span></div><div class="line"><span class="comment">//         .............................................</span></div><div class="line"><span class="comment">//                  佛祖镇楼                  BUG辟易</span></div><div class="line"><span class="comment">//             佛曰:</span></div><div class="line"><span class="comment">//                  写字楼里写字间，写字间里程序员；</span></div><div class="line"><span class="comment">//                  程序人员写程序，又拿程序换酒钱。</span></div><div class="line"><span class="comment">//                  酒醒只在网上坐，酒醉还来网下眠；</span></div><div class="line"><span class="comment">//                  酒醉酒醒日复日，网上网下年复年。</span></div><div class="line"><span class="comment">//                  但愿老死电脑间，不愿鞠躬老板前；</span></div><div class="line"><span class="comment">//                  奔驰宝马贵者趣，公交自行程序员。</span></div><div class="line"><span class="comment">//                  别人笑我忒疯癫，我笑自己命太贱；</span></div><div class="line"><span class="comment">//                  不见满街漂亮妹，哪个归得程序员？</span></div></pre></td></tr></table></figure>
<h2 id="2、佛系编程-永无bug"><a href="#2、佛系编程-永无bug" class="headerlink" title="2、佛系编程 永无bug"></a>2、佛系编程 永无bug</h2><h4 id="No-Code"><a href="#No-Code" class="headerlink" title="No Code"></a>No Code</h4><p>No code is the best way to write secure and reliable applications. Write nothing; deploy nowhere.</p>
<h4 id="Getting-Started"><a href="#Getting-Started" class="headerlink" title="Getting Started"></a>Getting Started</h4><p>Start by not writing any code.</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"></div></pre></td></tr></table></figure>
<p>This is just an example application, but imagine it doing anything you want. Adding new features is easy too:</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"></div></pre></td></tr></table></figure>
<p>The possibilities are endless.</p>
<h4 id="Building-the-Application"><a href="#Building-the-Application" class="headerlink" title="Building the Application"></a>Building the Application</h4><p>Now that you have not done anything it’s time to build your application:</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"></div></pre></td></tr></table></figure>
<p>Yep. That’s it. You should see the following output:</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"></div></pre></td></tr></table></figure>
<h4 id="Deploying"><a href="#Deploying" class="headerlink" title="Deploying"></a>Deploying</h4><p>While you still have not done anything it’s time to deploy your application. By running the following command you can deploy your application absolutely nowhere.</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"></div></pre></td></tr></table></figure>
<p>It’s that simple. And when it comes time to scale the application, all you have to do is:</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"></div></pre></td></tr></table></figure>
<p>I know right?</p>
<h4 id="Contributing"><a href="#Contributing" class="headerlink" title="Contributing"></a>Contributing</h4><p>You don’t.</p>
]]></content>
    
    <summary type="html">
    
      &lt;pre&gt;&lt;code&gt;这是崔斯特的第三十五篇原创文章
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;到底哪错了  (๑• . •๑)&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/pTw3VCX.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="编程" scheme="https://zhangslob.github.io/categories/%E7%BC%96%E7%A8%8B/"/>
    
    
      <category term="编程" scheme="https://zhangslob.github.io/tags/%E7%BC%96%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>学点算法之队列的学习及应用</title>
    <link href="https://zhangslob.github.io/2018/03/06/%E5%AD%A6%E7%82%B9%E7%AE%97%E6%B3%95%E4%B9%8B%E9%98%9F%E5%88%97%E7%9A%84%E5%AD%A6%E4%B9%A0%E5%8F%8A%E5%BA%94%E7%94%A8/"/>
    <id>https://zhangslob.github.io/2018/03/06/学点算法之队列的学习及应用/</id>
    <published>2018-03-06T12:54:00.000Z</published>
    <updated>2018-03-06T14:00:52.245Z</updated>
    
    <content type="html"><![CDATA[<pre><code>这是崔斯特的第三十四篇原创文章
</code></pre><p>从<code>约瑟夫问题</code>开始说起  (๑• . •๑)</p>
<p><img src="https://i.imgur.com/u6F1U4g.png" alt=""></p>
<a id="more"></a>
<h1 id="约瑟夫问题"><a href="#约瑟夫问题" class="headerlink" title="约瑟夫问题"></a>约瑟夫问题</h1><p><strong><a href="https://zh.wikipedia.org/wiki/%E7%BA%A6%E7%91%9F%E5%A4%AB%E6%96%AF%E9%97%AE%E9%A2%98" target="_blank" rel="external">约瑟夫问题</a></strong></p>
<p>有 n 个囚犯站成一个圆圈，准备处决。首先从一个人开始，越过k-2个人（因为第一个人已经被越过），并杀掉第k个人。接着，再越过 k-1个人，并杀掉第k个人。这个过程沿着圆圈一直进行，直到最终只剩下一个人留下，这个人就可以继续活着。</p>
<p>问题是，给定了n和k，一开始要站在什么地方才能避免被处决？</p>
<blockquote>
<p>这个问题是以弗拉维奥·约瑟夫命名的，它是1世纪的一名犹太历史学家。他在自己的日记中写道，他和他的40个战友被罗马军队包围在洞中。他们讨论是自杀还是被俘，最终决定自杀，并以抽签的方式决定谁杀掉谁。约瑟夫斯和另外一个人是最后两个留下的人。约瑟夫斯说服了那个人，<em>他们将向罗马军队投降，不再自杀</em>。约瑟夫斯把他的存活归因于运气或天意，<em>他不知道是哪一个</em>。</p>
</blockquote>
<h1 id="队列是什么"><a href="#队列是什么" class="headerlink" title="队列是什么"></a>队列是什么</h1><p>这道题有多种解法，这里先不说别的，要引出今天的主角——队列。队列的定义很好理解：</p>
<blockquote>
<p>队列是项的有序结合，其中添加新项的一端称为队尾，移除项的一端称为队首。当一个元素从队尾进入队列时，一直向队首移动，直到它成为下一个需要移除的元素为止。</p>
</blockquote>
<p>队列抽象数据类型由以下结构和操作定义。如上所述，队列被构造为在队尾添加项的有序集合，并且从队首移除。队列保持 FIFO 排序属性。 队列操作如下。</p>
<ul>
<li>Queue() 创建一个空的新队列。 它不需要参数，并返回一个空队列。</li>
<li>enqueue(item) 将新项添加到队尾。 它需要 item 作为参数，并不返回任何内容。</li>
<li>dequeue() 从队首移除项。它不需要参数并返回 item。 队列被修改。</li>
<li>isEmpty() 查看队列是否为空。它不需要参数，并返回布尔值。</li>
<li>size() 返回队列中的项数。它不需要参数，并返回一个整数。</li>
</ul>
<p><img src="https://i.imgur.com/KkagGoc.png" alt=""></p>
<h1 id="队列的Python算法实现"><a href="#队列的Python算法实现" class="headerlink" title="队列的Python算法实现"></a>队列的Python算法实现</h1><p>为了实现队列抽象数据类型创建一个新类</p>
<p><a href="https://github.com/bnmnetp/pythonds/blob/master/basic/queue.py" target="_blank" rel="external">pythonds/basic/queue.py</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Queue</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></div><div class="line">        self.items = []</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">isEmpty</span><span class="params">(self)</span>:</span></div><div class="line">        <span class="keyword">return</span> self.items == []</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">enqueue</span><span class="params">(self, item)</span>:</span></div><div class="line">        self.items.insert(<span class="number">0</span>,item)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">dequeue</span><span class="params">(self)</span>:</span></div><div class="line">        <span class="keyword">return</span> self.items.pop()</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">size</span><span class="params">(self)</span>:</span></div><div class="line">        <span class="keyword">return</span> len(self.items)</div></pre></td></tr></table></figure>
<p>想明白了其实就是对 list 的简单操作</p>
<h1 id="如何活到最后"><a href="#如何活到最后" class="headerlink" title="如何活到最后"></a>如何活到最后</h1><p>那我们回到上面的问题，如果是你，你要如何选择并活到最后呢？</p>
<p>我们的程序将输入名称列表和一个称为 <code>num</code> 常量用于报数。它将返回以 <code>num</code> 为单位重复报数后剩余的最后一个人的姓名。</p>
<p>假设第一个人是<code>a</code>。从他开始计数，<code>a</code>将先出列再入队列，把他放在队列的最后。经过 <code>num</code> 次的出队入队后，前面的人将被永久移除队列。并且另一个周期开始，继续此过程，直到只剩下一个名字（队列的大小为 1）。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> pythonds.basic.queue <span class="keyword">import</span> Queue</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">hotPotato</span><span class="params">(namelist, num)</span>:</span></div><div class="line">    simqueue = Queue()</div><div class="line">    <span class="keyword">for</span> name <span class="keyword">in</span> namelist:</div><div class="line">        simqueue.enqueue(name)</div><div class="line"></div><div class="line">    <span class="keyword">while</span> simqueue.size() &gt; <span class="number">1</span>:</div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(num):</div><div class="line">            simqueue.enqueue(simqueue.dequeue())</div><div class="line">        simqueue.dequeue()</div><div class="line"></div><div class="line">    <span class="keyword">return</span> simqueue.dequeue()</div><div class="line"></div><div class="line"></div><div class="line">print(hotPotato([<span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'c'</span>, <span class="string">'d'</span>, <span class="string">'e'</span>, <span class="string">'f'</span>, <span class="string">'g'</span>, <span class="string">'h'</span>, <span class="string">'i'</span>, <span class="string">'j'</span>], <span class="number">7</span>))</div><div class="line"></div><div class="line"><span class="comment"># output: f</span></div></pre></td></tr></table></figure>
<h1 id="其他解法"><a href="#其他解法" class="headerlink" title="其他解法"></a>其他解法</h1><p>比较简单的做法是用循环单链表模拟整个过程，时间复杂度是O(n*m)。如果只是想求得最后剩下的人，则可以用数学推导的方式得出公式。先看看模拟过程的解法。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># -*- coding: utf-8 -*- </span></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Node</span><span class="params">(object)</span>:</span></div><div class="line">	<span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, value)</span>:</span></div><div class="line">		self.value = value </div><div class="line">		self.next = <span class="keyword">None</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_linkList</span><span class="params">(n)</span>:</span></div><div class="line">	head = Node(<span class="number">1</span>)</div><div class="line">	pre = head</div><div class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">2</span>, n+<span class="number">1</span>):</div><div class="line">		newNode = Node(i)</div><div class="line">		pre.next= newNode</div><div class="line">		pre = newNode</div><div class="line">	pre.next = head</div><div class="line">	<span class="keyword">return</span> head</div><div class="line"></div><div class="line">n = <span class="number">5</span> <span class="comment">#总的个数</span></div><div class="line">m = <span class="number">2</span> <span class="comment">#数的数目</span></div><div class="line"></div><div class="line"><span class="keyword">if</span> m == <span class="number">1</span>: <span class="comment">#如果是1的话，特殊处理，直接输出</span></div><div class="line">	print(n)  </div><div class="line"><span class="keyword">else</span>:</div><div class="line">	head = create_linkList(n)</div><div class="line">	pre = <span class="keyword">None</span></div><div class="line">	cur = head</div><div class="line">	<span class="keyword">while</span> cur.next != cur: <span class="comment">#终止条件是节点的下一个节点指向本身</span></div><div class="line">		<span class="keyword">for</span> i <span class="keyword">in</span> range(m<span class="number">-1</span>):</div><div class="line">			pre =  cur</div><div class="line">			cur = cur.next</div><div class="line">		print(cur.value)</div><div class="line">		pre.next = cur.next</div><div class="line">		cur.next = <span class="keyword">None</span></div><div class="line">		cur = pre.next</div><div class="line">	print(cur.value)</div></pre></td></tr></table></figure>
<h2 id="作业"><a href="#作业" class="headerlink" title="作业"></a>作业</h2><p>假设实验室里有一台打印机供学生共性。当学生向共享打印机发送打印任务时，任务被放置在队列中以便以先来先服务的方式被处理。如何才能通过python程序模拟的方式得到每次提交任务的平均等待时间呢？（平均等待时间不包括打印本身的时间，仅指在队列中排队的时间。）<br>我们假定：</p>
<ul>
<li>学生们每次打印的页数在1到20页之间。</li>
<li>打印机平均每小时会收到20个打印请求，即平均每180秒1个请求。</li>
<li>每秒新增任务的可能性相等，即任务的产生为独立同分布</li>
<li>打印机的打印速度恒定。</li>
</ul>
<p>挖坑，要一起来填吗？</p>
<p><img src="https://i.imgur.com/83UUU6k.jpg" alt=""></p>
]]></content>
    
    <summary type="html">
    
      &lt;pre&gt;&lt;code&gt;这是崔斯特的第三十四篇原创文章
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;从&lt;code&gt;约瑟夫问题&lt;/code&gt;开始说起  (๑• . •๑)&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/u6F1U4g.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="算法" scheme="https://zhangslob.github.io/categories/%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="算法" scheme="https://zhangslob.github.io/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="队列" scheme="https://zhangslob.github.io/tags/%E9%98%9F%E5%88%97/"/>
    
  </entry>
  
  <entry>
    <title>Scrapy源码（2）——爬虫开始的地方</title>
    <link href="https://zhangslob.github.io/2018/02/26/Scrapy%E6%BA%90%E7%A0%81%EF%BC%882%EF%BC%89%E2%80%94%E2%80%94%E7%88%AC%E8%99%AB%E5%BC%80%E5%A7%8B%E7%9A%84%E5%9C%B0%E6%96%B9/"/>
    <id>https://zhangslob.github.io/2018/02/26/Scrapy源码（2）——爬虫开始的地方/</id>
    <published>2018-02-26T14:48:13.000Z</published>
    <updated>2018-02-26T15:14:48.399Z</updated>
    
    <content type="html"><![CDATA[<pre><code>这是崔斯特的第三十三篇原创文章
</code></pre><p>开始学习<code>Scrapy</code>源码  (๑• . •๑)</p>
<p><img src="https://i.imgur.com/5wP0fKB.png" alt=""></p>
<a id="more"></a>
<h1 id="Scrapy运行命令"><a href="#Scrapy运行命令" class="headerlink" title="Scrapy运行命令"></a>Scrapy运行命令</h1><p>一般来说，运行Scrapy项目的写法有，（这里不考虑从脚本运行Scrapy）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">Usage examples:</div><div class="line"></div><div class="line">$ scrapy crawl myspider</div><div class="line">[ ... myspider starts crawling ... ]</div><div class="line"></div><div class="line">$ scrapy runspider myspider.py</div><div class="line">[ ... spider starts crawling ... ]</div></pre></td></tr></table></figure>
<p>但是更好的写法是，新建一个Python文件，如下，（便于调试）<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> scrapy <span class="keyword">import</span> cmdline</div><div class="line"></div><div class="line">cmdline.execute(<span class="string">"scrapy crawl myspider"</span>.split())</div></pre></td></tr></table></figure></p>
<p>很容易就发现，Scrapy运行文件是<code>cmdline.py</code>文件里面的<code>execute()</code>函数，下面学习下这个函数在做什么。</p>
<h1 id="分析源码"><a href="#分析源码" class="headerlink" title="分析源码"></a>分析源码</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">execute</span><span class="params">(argv=None, settings=None)</span>:</span></div><div class="line">    <span class="keyword">if</span> argv <span class="keyword">is</span> <span class="keyword">None</span>:</div><div class="line">        argv = sys.argv</div><div class="line"></div><div class="line">    <span class="comment"># --- backwards compatibility for scrapy.conf.settings singleton ---</span></div><div class="line">    <span class="keyword">if</span> settings <span class="keyword">is</span> <span class="keyword">None</span> <span class="keyword">and</span> <span class="string">'scrapy.conf'</span> <span class="keyword">in</span> sys.modules:</div><div class="line">        <span class="keyword">from</span> scrapy <span class="keyword">import</span> conf</div><div class="line">        <span class="keyword">if</span> hasattr(conf, <span class="string">'settings'</span>):</div><div class="line">            settings = conf.settings</div><div class="line">    <span class="comment"># ------------------------------------------------------------------</span></div></pre></td></tr></table></figure>
<p>寻找 <code>scrapy.conf</code>配置文件，argv直接取sys.argv</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">if</span> settings <span class="keyword">is</span> <span class="keyword">None</span>:</div><div class="line">    settings = get_project_settings()</div><div class="line">    <span class="comment"># set EDITOR from environment if available</span></div><div class="line">    <span class="keyword">try</span>:</div><div class="line">        editor = os.environ[<span class="string">'EDITOR'</span>]</div><div class="line">    <span class="keyword">except</span> KeyError: <span class="keyword">pass</span></div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        settings[<span class="string">'EDITOR'</span>] = editor</div><div class="line">check_deprecated_settings(settings)</div><div class="line"></div><div class="line"><span class="comment"># --- backwards compatibility for scrapy.conf.settings singleton ---</span></div><div class="line"><span class="keyword">import</span> warnings</div><div class="line"><span class="keyword">from</span> scrapy.exceptions <span class="keyword">import</span> ScrapyDeprecationWarning</div><div class="line"><span class="keyword">with</span> warnings.catch_warnings():</div><div class="line">    warnings.simplefilter(<span class="string">"ignore"</span>, ScrapyDeprecationWarning)</div><div class="line">    <span class="keyword">from</span> scrapy <span class="keyword">import</span> conf</div><div class="line">    conf.settings = settings</div><div class="line"><span class="comment"># ------------------------------------------------------------------</span></div></pre></td></tr></table></figure>
<blockquote>
<p>set EDITOR from environment if available</p>
</blockquote>
<p>读取<code>settings</code>设置文件，导入项目，调用<code>get_project_settings()</code>函数，此处为<code>utils</code>文件夹下的<code>project.py</code>文件：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_project_settings</span><span class="params">()</span>:</span></div><div class="line">    <span class="keyword">if</span> ENVVAR <span class="keyword">not</span> <span class="keyword">in</span> os.environ:</div><div class="line">        project = os.environ.get(<span class="string">'SCRAPY_PROJECT'</span>, <span class="string">'default'</span>)</div><div class="line">        init_env(project)</div></pre></td></tr></table></figure>
<blockquote>
<p>project.py</p>
</blockquote>
<p><code>init_env()</code> 函数如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">init_env</span><span class="params">(project=<span class="string">'default'</span>, set_syspath=True)</span>:</span></div><div class="line">    <span class="string">"""Initialize environment to use command-line tool from inside a project</span></div><div class="line">    dir. This sets the Scrapy settings module and modifies the Python path to</div><div class="line">    be able to locate the project module.</div><div class="line">    """</div><div class="line">    cfg = get_config()</div><div class="line">    <span class="keyword">if</span> cfg.has_option(<span class="string">'settings'</span>, project):</div><div class="line">        os.environ[<span class="string">'SCRAPY_SETTINGS_MODULE'</span>] = cfg.get(<span class="string">'settings'</span>, project)</div><div class="line">    closest = closest_scrapy_cfg()</div><div class="line">    <span class="keyword">if</span> closest:</div><div class="line">        projdir = os.path.dirname(closest)</div><div class="line">        <span class="keyword">if</span> set_syspath <span class="keyword">and</span> projdir <span class="keyword">not</span> <span class="keyword">in</span> sys.path:</div><div class="line">            sys.path.append(projdir)</div></pre></td></tr></table></figure>
<blockquote>
<p>conf.py</p>
</blockquote>
<p>如注释所说，初始化环境,循环递归找到用户项目中的配置文件<code>settings.py</code>,并且将其设置到环境变量<code>Scrapy settings module</code>中。然后修改Python路径，确保能找到项目模块。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">settings = Settings()</div><div class="line">settings_module_path = os.environ.get(ENVVAR)</div><div class="line"><span class="keyword">if</span> settings_module_path:</div><div class="line">    settings.setmodule(settings_module_path, priority=<span class="string">'project'</span>)</div><div class="line"></div><div class="line"><span class="comment"># <span class="doctag">XXX:</span> remove this hack</span></div><div class="line">pickled_settings = os.environ.get(<span class="string">"SCRAPY_PICKLED_SETTINGS_TO_OVERRIDE"</span>)</div><div class="line"><span class="keyword">if</span> pickled_settings:</div><div class="line">    settings.setdict(pickle.loads(pickled_settings), priority=<span class="string">'project'</span>)</div><div class="line"></div><div class="line"><span class="comment"># <span class="doctag">XXX:</span> deprecate and remove this functionality</span></div><div class="line">env_overrides = &#123;k[<span class="number">7</span>:]: v <span class="keyword">for</span> k, v <span class="keyword">in</span> os.environ.items() <span class="keyword">if</span></div><div class="line">                 k.startswith(<span class="string">'SCRAPY_'</span>)&#125;</div><div class="line"><span class="keyword">if</span> env_overrides:</div><div class="line">    settings.setdict(env_overrides, priority=<span class="string">'project'</span>)</div><div class="line"></div><div class="line"><span class="keyword">return</span> settings</div></pre></td></tr></table></figure>
<blockquote>
<p>project.py</p>
</blockquote>
<p>至此，<code>get_project_settings()</code>该函数结束，如函数名字一样，最后返回项目配置，到此为止，接着往下看</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">inproject = inside_project()</div><div class="line">cmds = _get_commands_dict(settings, inproject)</div><div class="line">cmdname = _pop_command_name(argv)</div><div class="line">parser = optparse.OptionParser(formatter=optparse.TitledHelpFormatter(), \</div><div class="line">    conflict_handler=<span class="string">'resolve'</span>)</div><div class="line"><span class="keyword">if</span> <span class="keyword">not</span> cmdname:</div><div class="line">    _print_commands(settings, inproject)</div><div class="line">    sys.exit(<span class="number">0</span>)</div><div class="line"><span class="keyword">elif</span> cmdname <span class="keyword">not</span> <span class="keyword">in</span> cmds:</div><div class="line">    _print_unknown_command(settings, cmdname, inproject)</div><div class="line">    sys.exit(<span class="number">2</span>)</div></pre></td></tr></table></figure>
<p>导入相应的module爬虫模块（inside_project）</p>
<p>执行环境是否在项目中，主要检查scrapy.cfg配置文件是否存在，读取commands文件夹，把所有的命令类转换为<code>{cmd_name: cmd_instance}</code>的字典</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">cmd = cmds[cmdname]</div><div class="line">parser.usage = <span class="string">"scrapy %s %s"</span> % (cmdname, cmd.syntax())</div><div class="line">parser.description = cmd.long_desc()</div><div class="line">settings.setdict(cmd.default_settings, priority=<span class="string">'command'</span>)</div><div class="line">cmd.settings = settings</div><div class="line">cmd.add_options(parser)</div><div class="line">opts, args = parser.parse_args(args=argv[<span class="number">1</span>:])</div><div class="line">_run_print_help(parser, cmd.process_options, args, opts)</div></pre></td></tr></table></figure>
<p>根据命令名称找到对应的命令实例，设置项目配置和级别为command，添加解析规则，解析命令参数，并交由Scrapy命令实例处理。</p>
<p>最后，看看下面这段代码。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">cmd.crawler_process = CrawlerProcess(settings)</div><div class="line">_run_print_help(parser, _run_command, cmd, args, opts)</div><div class="line">sys.exit(cmd.exitcode)</div></pre></td></tr></table></figure>
<p>初始化<code>CrawlerProcess</code>实例，将对应的命令执行，这里是<code>crawl</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">_run_command</span><span class="params">(cmd, args, opts)</span>:</span></div><div class="line">    <span class="keyword">if</span> opts.profile:</div><div class="line">        _run_command_profiled(cmd, args, opts)</div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        cmd.run(args, opts)</div></pre></td></tr></table></figure>
<p>看到这，想起了文档中的介绍 <a href="https://doc.scrapy.org/en/latest/topics/practices.html#run-scrapy-from-a-script" target="_blank" rel="external">Run Scrapy from a script</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Here’s an example showing how to run a single spider with it.</span></div><div class="line"></div><div class="line"><span class="keyword">import</span> scrapy</div><div class="line"><span class="keyword">from</span> scrapy.crawler <span class="keyword">import</span> CrawlerProcess</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">MySpider</span><span class="params">(scrapy.Spider)</span>:</span></div><div class="line">    <span class="comment"># Your spider definition</span></div><div class="line">    ...</div><div class="line"></div><div class="line">process = CrawlerProcess(&#123;</div><div class="line">    <span class="string">'USER_AGENT'</span>: <span class="string">'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'</span></div><div class="line">&#125;)</div><div class="line"></div><div class="line">process.crawl(MySpider)</div><div class="line">process.start() <span class="comment"># the script will block here until the crawling is finished</span></div></pre></td></tr></table></figure>
<p>所以Scrapy爬虫运行都有用使用到<code>CrawlerProcess</code>，想要深入了解可以去看看源码 <a href="https://github.com/scrapy/scrapy/blob/1.5/scrapy/crawler.py#L225" target="_blank" rel="external">scrapy/scrapy/crawler.py</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="string">"""</span></div><div class="line">A class to run multiple scrapy crawlers in a process simultaneously.</div><div class="line"></div><div class="line">This class extends :class:`~scrapy.crawler.CrawlerRunner` by adding support</div><div class="line">for starting a Twisted `reactor`_ and handling shutdown signals, like the</div><div class="line">keyboard interrupt command Ctrl-C. It also configures top-level logging.</div><div class="line"></div><div class="line">This utility should be a better fit than</div><div class="line">:class:`~scrapy.crawler.CrawlerRunner` if you aren't running another</div><div class="line">Twisted `reactor`_ within your application.</div><div class="line"></div><div class="line">The CrawlerProcess object must be instantiated with a</div><div class="line">:class:`~scrapy.settings.Settings` object.</div><div class="line"></div><div class="line">:param install_root_handler: whether to install root logging handler</div><div class="line">    (default: True)</div><div class="line"></div><div class="line">This class shouldn't be needed (since Scrapy is responsible of using it</div><div class="line">accordingly) unless writing scripts that manually handle the crawling</div><div class="line">process. See :ref:`run-from-script` for an example.</div><div class="line">"""</div></pre></td></tr></table></figure>
<p>最后，附上Scrapy的路径图</p>
<p><img src="https://i.imgur.com/bG560BG.png" alt=""></p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>简单来说，有这么几步：</p>
<ol>
<li>读取配置文件，应用到爬虫中</li>
<li>把所有的命令类转换名称与实例字典</li>
<li>初始化<code>CrawlerProcess</code>实例，运行爬虫</li>
</ol>
<p>(看的头疼，好多函数名记不住)</p>
<p>回顾：</p>
<ol>
<li><a href="https://zhangslob.github.io/2018/02/24/Scrapy%E6%BA%90%E7%A0%81%EF%BC%881%EF%BC%89%E2%80%94%E2%80%94%E7%88%AC%E8%99%AB%E6%B5%81%E7%A8%8B%E6%A6%82%E8%A7%88/">Scrapy源码（1）——爬虫流程概览</a></li>
<li>Scrapy源码（2）——爬虫开始的地方</li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;pre&gt;&lt;code&gt;这是崔斯特的第三十三篇原创文章
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;开始学习&lt;code&gt;Scrapy&lt;/code&gt;源码  (๑• . •๑)&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/5wP0fKB.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Scrapy" scheme="https://zhangslob.github.io/categories/Scrapy/"/>
    
    
      <category term="爬虫" scheme="https://zhangslob.github.io/tags/%E7%88%AC%E8%99%AB/"/>
    
      <category term="Scrapy" scheme="https://zhangslob.github.io/tags/Scrapy/"/>
    
  </entry>
  
  <entry>
    <title>Scrapy源码（1）——爬虫流程概览</title>
    <link href="https://zhangslob.github.io/2018/02/24/Scrapy%E6%BA%90%E7%A0%81%EF%BC%881%EF%BC%89%E2%80%94%E2%80%94%E7%88%AC%E8%99%AB%E6%B5%81%E7%A8%8B%E6%A6%82%E8%A7%88/"/>
    <id>https://zhangslob.github.io/2018/02/24/Scrapy源码（1）——爬虫流程概览/</id>
    <published>2018-02-24T13:16:23.000Z</published>
    <updated>2018-02-26T15:15:04.711Z</updated>
    
    <content type="html"><![CDATA[<pre><code>这是崔斯特的第三十二篇原创文章
</code></pre><p>开始学习<code>Scrapy</code>源码  (๑• . •๑)</p>
<p><img src="https://i.imgur.com/5wP0fKB.png" alt=""></p>
<a id="more"></a>
<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>使用 <code>Scrapy</code> 已经有一段时间了，觉得自己有必要对源码好好的学习下了，所以写下记录，希望能加深自己的理解。</p>
<blockquote>
<p>Scrapy | A Fast and Powerful Scraping and Web Crawling Framework</p>
</blockquote>
<p>接下来说到的是最新版本： Scrapy 1.5，暂且把 <code>Spider</code> 称为 <strong>蜘蛛</strong>，而不是爬虫。</p>
<h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>Scrapy是一个开源爬虫框架，用于抓取网站并提取有用的结构化数据，如数据挖掘，信息处理或历史档案。</p>
<p>尽管Scrapy最初是为<a href="https://en.wikipedia.org/wiki/Web_scraping" target="_blank" rel="external">网页抓取</a>设计的，但它也可以用于使用API（如<a href="https://affiliate-program.amazon.com/gp/advertising/api/detail/main.html" target="_blank" rel="external">Amazon Associates Web Services</a>）或作为通用网络抓取工具提取数据。</p>
<p>一个最简单的例子，相信大家都写过</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> scrapy</div><div class="line"></div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">QuotesSpider</span><span class="params">(scrapy.Spider)</span>:</span></div><div class="line">    name = <span class="string">"quotes"</span></div><div class="line">    start_urls = [</div><div class="line">        <span class="string">'http://quotes.toscrape.com/tag/humor/'</span>,</div><div class="line">    ]</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></div><div class="line">        <span class="keyword">for</span> quote <span class="keyword">in</span> response.css(<span class="string">'div.quote'</span>):</div><div class="line">            <span class="keyword">yield</span> &#123;</div><div class="line">                <span class="string">'text'</span>: quote.css(<span class="string">'span.text::text'</span>).extract_first(),</div><div class="line">                <span class="string">'author'</span>: quote.xpath(<span class="string">'span/small/text()'</span>).extract_first(),</div><div class="line">            &#125;</div><div class="line"></div><div class="line">        next_page = response.css(<span class="string">'li.next a::attr("href")'</span>).extract_first()</div><div class="line">        <span class="keyword">if</span> next_page <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</div><div class="line">            <span class="keyword">yield</span> response.follow(next_page, self.parse)</div></pre></td></tr></table></figure>
<p>一般来说，创建一个Scrapy项目需要如下流程：</p>
<ol>
<li>使用<code>scrapy startproject spider</code>创建爬虫模板</li>
<li>爬虫类继承<code>scrapy.Spider</code>，重写<code>parse</code>方法和逻辑</li>
<li><code>parse</code>方法中<code>yield</code>或<code>return</code>字典、<code>Request</code>、<code>Item</code></li>
<li>自定义<code>Item</code>、<code>Middlewares</code>、<code>Pipelines</code>等</li>
<li>使用<code>scrapy crawl &lt;spider_name&gt;</code>或新建文件<code>cmdline.execute(&quot;scrapy crawl spider_name&quot;.split())</code>运行（便于调试）</li>
<li>其它</li>
</ol>
<h1 id="架构概述"><a href="#架构概述" class="headerlink" title="架构概述"></a>架构概述</h1><p><img src="https://doc.scrapy.org/en/latest/_images/scrapy_architecture_02.png" alt=""></p>
<p>这是一张非常经典的图，基本上说到Scrapy都会用到它，来源于<a href="https://doc.scrapy.org/en/latest/topics/architecture.html#data-flow" target="_blank" rel="external">Architecture overview</a></p>
<h2 id="核心组件（Components）"><a href="#核心组件（Components）" class="headerlink" title="核心组件（Components）"></a>核心组件（Components）</h2><ul>
<li><code>Scrapy Engine</code>：<strong>引擎</strong>，负责控制系统所有组件之间的数据流，并在发生某些操作时触发事件；</li>
<li><code>Scheduler</code>：<strong>调度器</strong>，接收来自引擎的请求，并将它们排入队列，以便在引擎请求它们时将它们提供给它们（也提供给引擎）；</li>
<li><code>Downloader</code>：<strong>下载器</strong>，负责从网络上获取网页并将它们返回到引擎，然后引擎将它们返回给蜘蛛/spiders；</li>
<li><code>Spiders</code>：<strong>蜘蛛</strong>，是用户编写的自定义类，用于解析响应并从中提取项目（也称为抓取的项目）或追加其他请求；</li>
<li><code>Item Pipeline</code>：<strong>管道</strong>，负责输出结构化数据，可自定义输出位置，典型的任务包括清理，验证和持久性；</li>
<li><code>Downloader middlewares</code>：<strong>下载中间件</strong>，位于引擎和下载器之间的特定钩子/hooks，当它们从引擎传递到下载器时处理请求，以及从下载器传递到引擎的响应，常用于如下情况：<ul>
<li>在将请求发送到下载器之前处理请求（即在Scrapy将请求发送到网站之前）;</li>
<li>在将其传递给蜘蛛之前改变接收到的响应;</li>
<li>发送新的请求，而不是将接收到的响应传递给蜘蛛;</li>
<li>向蜘蛛传递响应而不需要获取网页;</li>
<li>默默地放下一些请求。</li>
</ul>
</li>
<li><code>Spider middlewares</code>：<strong>Spider中间件</strong>，特定的钩子，位于引擎和蜘蛛之间，能够处理蜘蛛输入（响应）和输出（项目和请求），常用于如下情况：<ul>
<li>spider回调的后处理输出 更改/添加/删除请求或items;</li>
<li>后处理start_requests;</li>
<li>处理蜘蛛异常;</li>
<li>根据响应内容为一些请求调用errback而不是callback。</li>
</ul>
</li>
<li><code>Event-driven networking</code>：<strong>事件驱动的网络</strong>，Scrapy是用Twisted编写的，这是一个流行的事件驱动的Python网络框架。 因此，它使用非阻塞（又称异步）代码来实现并发。</li>
</ul>
<blockquote>
<p>Twisted is an event-driven networking engine written in Python and licensed under the open source ​MIT license. </p>
</blockquote>
<h2 id="数据流（Data-flow）"><a href="#数据流（Data-flow）" class="headerlink" title="数据流（Data flow）"></a>数据流（Data flow）</h2><p>Scrapy中的数据流由执行引擎控制，如下所示：</p>
<ol>
<li>引擎获取最初的请求从蜘蛛抓取（<code>start_urls</code>）。</li>
<li>引擎在调度程序中调度请求，并要求下一个请求进行采集。</li>
<li>调度器将下一个请求返回给引擎。</li>
<li>引擎将请求发送到下载器，通过下载器中间件。</li>
<li>一旦页面完成下载，<code>Downloader</code>会生成一个响应（包含该页面）并将其发送到引擎，并通过<code>Downloader Middlewares</code>。</li>
<li>引擎从<code>Downloader</code>收到响应并将其发送给<code>Spider</code>进行处理，并通过<code>Spider Middleware</code>传递。</li>
<li><code>Spider</code>处理响应，并通过<code>Spider</code>中间件将抓取的项目和新的请求（后续）返回给引擎。</li>
<li>引擎将处理后的项目发送到项目管道，然后将处理后的请求发送到调度程序，并要求可能的下一个请求进行采集。</li>
<li>该过程重复（从第1步开始），直到调度器没有更多请求。</li>
</ol>
<p>找到一张图，便于理解：</p>
<p><img src="https://i.imgur.com/taeQOrA.png" alt=""></p>
<p>第一期差不多就到这了，没有说很多代码，主要是宏观上来观察 <code>Scrapy</code> 的架构，是如何运行。之后会更多的查看Scrapy的源代码，就近是如何采集数据的。</p>
<p>（内心有点小恐慌，不知道会写成什么样子。）</p>
<h1 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h1><p>关于如何阅读项目源代码，找到一篇不错的文章，共享：<a href="https://zhijianshusheng.github.io/2017/06/07/2017/6/%E5%A6%82%E4%BD%95%E9%98%85%E8%AF%BB%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE/" target="_blank" rel="external">如何阅读开源项目</a></p>
<p>主要是这几部分：</p>
<ol>
<li>看：静态对代码进行分析，看相关资料，代码逻辑。</li>
<li>跑：将项目在IDE里面跑起来，通过IDE调试参数，加Log等。</li>
<li>查：阅读过程中肯定会遇到不懂的，这时候需要通过搜索引擎来解决你的疑惑。</li>
</ol>
<p>回顾：</p>
<ol>
<li>Scrapy源码（1）——爬虫流程概览</li>
<li>Scrapy源码（2）——爬虫开始的地方</li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;pre&gt;&lt;code&gt;这是崔斯特的第三十二篇原创文章
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;开始学习&lt;code&gt;Scrapy&lt;/code&gt;源码  (๑• . •๑)&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/5wP0fKB.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Scrapy" scheme="https://zhangslob.github.io/categories/Scrapy/"/>
    
    
      <category term="爬虫" scheme="https://zhangslob.github.io/tags/%E7%88%AC%E8%99%AB/"/>
    
      <category term="Scrapy" scheme="https://zhangslob.github.io/tags/Scrapy/"/>
    
  </entry>
  
</feed>
